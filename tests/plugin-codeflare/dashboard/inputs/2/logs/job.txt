
2022-07-05 16:01:08 Starting Glue benchmark ---------------
model: roberta-base
gluedata: glue_data
bucket: browsey
tasks: WNLI
seeds: 40 41 42 43
learning_rate: 2e-05
savemodel: True
ray_service: glue-cluster-ray-head:10001
S3 data looks good in bucket=browsey
 Found actor=DataRefsActor with state {'glue_data': 'Cached', 'roberta-base': 'Cached'}
2022-07-05 16:01:09 Submitted 4 subtasks
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Node ID: NodeID(314a5e8168e3a05c53f033cee658a763f1746ac8a371ac2c0b711b2d)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m GPU IDs: [0]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:01:11 Get glue_data data reference from data actor
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:01:11 Data: try cache get glue_data
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Node ID: NodeID(16ce70139c94f0dc07958d8a4b30d769dbb78ddef093a0555ae16d53)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m GPU IDs: [0]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:01:11 Get glue_data data reference from data actor
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:01:11 Data: try cache get glue_data
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Node ID: NodeID(e7542a493fe0dadf02f54e09bc01a53ec43d612755dd97f68450ec11)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m GPU IDs: [0]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:01:11 Get glue_data data reference from data actor
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:01:11 Data: try cache get glue_data
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:01:11 Data: done cache get glue_data length=405875765 took 0.19s
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Node ID: NodeID(c2f16e354d4acb44a38763f5fc699a8bec57de28c88317b0527b681b)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m GPU IDs: [0]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:01:11 Get glue_data data reference from data actor
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:01:11 Data: try cache get glue_data
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:01:11 Data: done cache get glue_data length=405875765 took 0.20s
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:01:11 Data: done cache get glue_data length=405875765 took 0.21s
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:01:11 Data: done cache get glue_data length=405875765 took 0.22s
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:01:11 Data: try unpack glue_data tarfile
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:01:11 Data: try unpack glue_data tarfile
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:01:11 Data: try unpack glue_data tarfile
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:01:11 Data: try unpack glue_data tarfile
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:01:23 Data: done unpack glue_data tarfile took 12.19s
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:01:23 Get roberta-base data reference from data actor
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:01:23 Data: try cache get roberta-base
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:01:24 Data: done cache get roberta-base length=1371970574 took 0.71s
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:01:24 Data: try unpack roberta-base tarfile
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:01:25 Data: done unpack glue_data tarfile took 13.97s
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:01:25 Get roberta-base data reference from data actor
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:01:25 Data: try cache get roberta-base
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:01:25 Data: done unpack glue_data tarfile took 14.26s
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:01:25 Get roberta-base data reference from data actor
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:01:25 Data: try cache get roberta-base
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:01:26 Data: done unpack glue_data tarfile took 14.50s
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:01:26 Get roberta-base data reference from data actor
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:01:26 Data: try cache get roberta-base
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:01:26 Data: done cache get roberta-base length=1371970574 took 0.64s
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:01:26 Data: done cache get roberta-base length=1371970574 took 0.63s
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:01:26 Data: done cache get roberta-base length=1371970574 took 0.66s
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:01:26 Data: try unpack roberta-base tarfile
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:01:26 Data: try unpack roberta-base tarfile
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:01:26 Data: try unpack roberta-base tarfile
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:02:03 Data: done unpack roberta-base tarfile took 37.56s
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Processing task WNLI seed 43 with model roberta-base
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Will not apply HSTS. The HSTS database must be a regular and non-world-writable file.
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m ERROR: could not open HSTS store at '/home/ray/.wget-hsts'. HSTS will be disabled.
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m --2022-07-05 16:02:03--  https://raw.githubusercontent.com/huggingface/transformers/b0892fa0e8df02d683e05e625b3903209bff362d/examples/text-classification/run_glue.py
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m HTTP request sent, awaiting response... 200 OK
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Length: 9504 (9.3K) [text/plain]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Saving to: â€˜run_glue.pyâ€™
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m      0K .........                                             100% 68.7M=0s
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 2022-07-05 16:02:03 (68.7 MB/s) - â€˜run_glue.pyâ€™ saved [9504/9504]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:02:03 Data: done unpack roberta-base tarfile took 36.40s
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Processing task WNLI seed 40 with model roberta-base
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m --2022-07-05 16:02:03--  https://raw.githubusercontent.com/huggingface/transformers/b0892fa0e8df02d683e05e625b3903209bff362d/examples/text-classification/run_glue.py
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m HTTP request sent, awaiting response... 200 OK
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Length: 9504 (9.3K) [text/plain]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Saving to: â€˜run_glue.pyâ€™
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m      0K .........                                             100% 52.4M=0s
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 2022-07-05 16:02:03 (52.4 MB/s) - â€˜run_glue.pyâ€™ saved [9504/9504]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:02:03 Data: done unpack roberta-base tarfile took 36.76s
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Processing task WNLI seed 41 with model roberta-base
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m --2022-07-05 16:02:03--  https://raw.githubusercontent.com/huggingface/transformers/b0892fa0e8df02d683e05e625b3903209bff362d/examples/text-classification/run_glue.py
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 185.199.109.133, 185.199.110.133, 185.199.111.133, ...
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m HTTP request sent, awaiting response... 200 OK
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Length: 9504 (9.3K) [text/plain]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Saving to: â€˜run_glue.pyâ€™
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m      0K .........                                             100% 72.3M=0s
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 2022-07-05 16:02:03 (72.3 MB/s) - â€˜run_glue.pyâ€™ saved [9504/9504]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:02:05 Data: done unpack roberta-base tarfile took 37.83s
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Processing task WNLI seed 42 with model roberta-base
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m --2022-07-05 16:02:05--  https://raw.githubusercontent.com/huggingface/transformers/b0892fa0e8df02d683e05e625b3903209bff362d/examples/text-classification/run_glue.py
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m HTTP request sent, awaiting response... 200 OK
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Length: 9504 (9.3K) [text/plain]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Saving to: â€˜run_glue.pyâ€™
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m      0K .........                                             100% 60.8M=0s
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 2022-07-05 16:02:05 (60.8 MB/s) - â€˜run_glue.pyâ€™ saved [9504/9504]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:07 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:07 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul05_16-02-07_mycluster-ray-worker-type-lwbrv', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=43, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "architectures": [
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   ],
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m }
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "architectures": [
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   ],
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m }
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:07 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:07 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:07 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul05_16-02-07_mycluster-ray-worker-type-9h8mt', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=40, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "architectures": [
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   ],
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m }
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "architectures": [
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   ],
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m }
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:07 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:07 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul05_16-02-07_mycluster-ray-worker-type-lncm6', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=41, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "architectures": [
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   ],
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m }
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "architectures": [
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   ],
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m }
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:07 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:07 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:09 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:09 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:09 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul05_16-02-09_mycluster-ray-worker-type-lt59j', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:09 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:09 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "architectures": [
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   ],
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m }
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:09 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:09 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "architectures": [
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   ],
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m }
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:09 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:09 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:09 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:12 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:12 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:12 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-0
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 100, 4889, 10, 7756, 149, 10, 33129, 4, 520, 38, 2468, 5, 7756, 66, 6, 24, 56, 10, 4683, 4, 2, 2, 133, 33129, 56, 10, 4683, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-1
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 10567, 1705, 75, 192, 5, 1289, 19, 7835, 11, 760, 9, 123, 142, 37, 16, 98, 765, 4, 2, 2, 10567, 16, 98, 765, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-2
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 249, 1128, 70, 9, 5, 5188, 453, 4, 252, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 2, 133, 249, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-3
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 21976, 3905, 7734, 18, 1246, 11, 960, 4, 91, 16882, 123, 13481, 4, 2, 2, 21976, 16882, 123, 13481, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-4
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 1779, 17734, 219, 1113, 1348, 5, 11657, 6, 69, 985, 21, 8416, 4, 264, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 2, 19456, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.062 s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-0
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 15160, 16, 3741, 29519, 19, 2549, 4, 85, 34, 7, 28, 17317, 4, 2, 2, 133, 2549, 34, 7, 28, 17317, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-1
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 35903, 6536, 15, 6470, 18, 1883, 53, 79, 222, 45, 1948, 4, 2, 2, 38621, 222, 45, 1948, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-2
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 387, 4774, 399, 75, 120, 5800, 19, 15282, 6, 54, 56, 847, 69, 160, 6, 142, 79, 2294, 8, 11590, 7, 2724, 4, 2, 2, 104, 2368, 2294, 8, 11590, 7, 2724, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-3
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 3084, 65, 9447, 622, 7, 28, 5074, 8, 20100, 4, 125, 10, 92, 892, 31, 5, 589, 9, 4222, 19902, 1655, 5839, 10648, 14, 14, 18, 2230, 141, 24, 817, 201, 619, 4, 2, 2, 1711, 18, 2230, 141, 622, 817, 201, 619, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-4
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 313, 1705, 75, 5258, 39, 979, 142, 37, 21, 98, 2016, 4, 2, 2, 133, 979, 21, 98, 2016, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.008 s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-0
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 100, 4889, 10, 7756, 149, 10, 33129, 4, 520, 38, 2468, 5, 7756, 66, 6, 24, 56, 10, 4683, 4, 2, 2, 133, 33129, 56, 10, 4683, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-1
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 10567, 1705, 75, 192, 5, 1289, 19, 7835, 11, 760, 9, 123, 142, 37, 16, 98, 765, 4, 2, 2, 10567, 16, 98, 765, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-2
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 249, 1128, 70, 9, 5, 5188, 453, 4, 252, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 2, 133, 249, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-3
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 21976, 3905, 7734, 18, 1246, 11, 960, 4, 91, 16882, 123, 13481, 4, 2, 2, 21976, 16882, 123, 13481, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-4
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 1779, 17734, 219, 1113, 1348, 5, 11657, 6, 69, 985, 21, 8416, 4, 264, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 2, 19456, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-0
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 100, 4889, 10, 7756, 149, 10, 33129, 4, 520, 38, 2468, 5, 7756, 66, 6, 24, 56, 10, 4683, 4, 2, 2, 133, 33129, 56, 10, 4683, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-1
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 10567, 1705, 75, 192, 5, 1289, 19, 7835, 11, 760, 9, 123, 142, 37, 16, 98, 765, 4, 2, 2, 10567, 16, 98, 765, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-2
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 249, 1128, 70, 9, 5, 5188, 453, 4, 252, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 2, 133, 249, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-3
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 21976, 3905, 7734, 18, 1246, 11, 960, 4, 91, 16882, 123, 13481, 4, 2, 2, 21976, 16882, 123, 13481, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: train-4
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 1779, 17734, 219, 1113, 1348, 5, 11657, 6, 69, 985, 21, 8416, 4, 264, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 2, 19456, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.087 s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-0
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 15160, 16, 3741, 29519, 19, 2549, 4, 85, 34, 7, 28, 17317, 4, 2, 2, 133, 2549, 34, 7, 28, 17317, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-1
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 35903, 6536, 15, 6470, 18, 1883, 53, 79, 222, 45, 1948, 4, 2, 2, 38621, 222, 45, 1948, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-2
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 387, 4774, 399, 75, 120, 5800, 19, 15282, 6, 54, 56, 847, 69, 160, 6, 142, 79, 2294, 8, 11590, 7, 2724, 4, 2, 2, 104, 2368, 2294, 8, 11590, 7, 2724, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-3
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 3084, 65, 9447, 622, 7, 28, 5074, 8, 20100, 4, 125, 10, 92, 892, 31, 5, 589, 9, 4222, 19902, 1655, 5839, 10648, 14, 14, 18, 2230, 141, 24, 817, 201, 619, 4, 2, 2, 1711, 18, 2230, 141, 622, 817, 201, 619, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-4
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 313, 1705, 75, 5258, 39, 979, 142, 37, 21, 98, 2016, 4, 2, 2, 133, 979, 21, 98, 2016, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.007 s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.062 s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-0
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 15160, 16, 3741, 29519, 19, 2549, 4, 85, 34, 7, 28, 17317, 4, 2, 2, 133, 2549, 34, 7, 28, 17317, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-1
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 35903, 6536, 15, 6470, 18, 1883, 53, 79, 222, 45, 1948, 4, 2, 2, 38621, 222, 45, 1948, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-2
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 387, 4774, 399, 75, 120, 5800, 19, 15282, 6, 54, 56, 847, 69, 160, 6, 142, 79, 2294, 8, 11590, 7, 2724, 4, 2, 2, 104, 2368, 2294, 8, 11590, 7, 2724, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-3
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 3084, 65, 9447, 622, 7, 28, 5074, 8, 20100, 4, 125, 10, 92, 892, 31, 5, 589, 9, 4222, 19902, 1655, 5839, 10648, 14, 14, 18, 2230, 141, 24, 817, 201, 619, 4, 2, 2, 1711, 18, 2230, 141, 622, 817, 201, 619, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   guid: dev-4
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 313, 1705, 75, 5258, 39, 979, 142, 37, 21, 98, 2016, 4, 2, 2, 133, 979, 21, 98, 2016, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:13 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.008 s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   guid: train-0
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 100, 4889, 10, 7756, 149, 10, 33129, 4, 520, 38, 2468, 5, 7756, 66, 6, 24, 56, 10, 4683, 4, 2, 2, 133, 33129, 56, 10, 4683, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   guid: train-1
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 10567, 1705, 75, 192, 5, 1289, 19, 7835, 11, 760, 9, 123, 142, 37, 16, 98, 765, 4, 2, 2, 10567, 16, 98, 765, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   guid: train-2
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 249, 1128, 70, 9, 5, 5188, 453, 4, 252, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 2, 133, 249, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   guid: train-3
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 21976, 3905, 7734, 18, 1246, 11, 960, 4, 91, 16882, 123, 13481, 4, 2, 2, 21976, 16882, 123, 13481, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   guid: train-4
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 1779, 17734, 219, 1113, 1348, 5, 11657, 6, 69, 985, 21, 8416, 4, 264, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 2, 19456, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.063 s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   guid: dev-0
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 15160, 16, 3741, 29519, 19, 2549, 4, 85, 34, 7, 28, 17317, 4, 2, 2, 133, 2549, 34, 7, 28, 17317, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   guid: dev-1
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 35903, 6536, 15, 6470, 18, 1883, 53, 79, 222, 45, 1948, 4, 2, 2, 38621, 222, 45, 1948, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   guid: dev-2
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 387, 4774, 399, 75, 120, 5800, 19, 15282, 6, 54, 56, 847, 69, 160, 6, 142, 79, 2294, 8, 11590, 7, 2724, 4, 2, 2, 104, 2368, 2294, 8, 11590, 7, 2724, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   guid: dev-3
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 3084, 65, 9447, 622, 7, 28, 5074, 8, 20100, 4, 125, 10, 92, 892, 31, 5, 589, 9, 4222, 19902, 1655, 5839, 10648, 14, 14, 18, 2230, 141, 24, 817, 201, 619, 4, 2, 2, 1711, 18, 2230, 141, 622, 817, 201, 619, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   guid: dev-4
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 313, 1705, 75, 5258, 39, 979, 142, 37, 21, 98, 2016, 4, 2, 2, 133, 979, 21, 98, 2016, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:15 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.007 s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:17 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:17 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:17 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:17 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:17 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:17 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:17 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:17 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:17 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:18 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  3.81it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:05,  3.77it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.02it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.06it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:05,  3.64it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.14it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.17it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.20it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  3.96it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.24it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.09it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.25it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.23it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.09it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.29it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.15it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.29it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.18it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.27it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.20it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:20 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:20 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:20 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:20 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:20 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:20 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:20 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:20 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:20 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.33it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.23it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.28it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.25it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:05,  3.74it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.27it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.17it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.05it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.29it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.07it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.19it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.30it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.23it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.12it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.25it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.31it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.14it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.26it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.30it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.28it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.18it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.30it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.29it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.17it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.30it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.33it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:04<00:00,  4.21it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.32it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.17it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.30it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.46it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.30it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:23,  4.65s/it]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.24it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:04<00:00,  4.19it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.26it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.42it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.28it/s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:23,  4.68s/it]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.21it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.14it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.20it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.32it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.18it/s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:23,  4.79s/it]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.29it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.23it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.29it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.33it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.24it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.32it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.34it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.29it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.26it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.33it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.30it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.24it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.21it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.30it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.33it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.35it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.24it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.56it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.35it/s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:22,  4.60s/it]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.20it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.42it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.23it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.36it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.32it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.22it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.37it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.33it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.23it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.24it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.29it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.40it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.23it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.27it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.36it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.27it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.26it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.37it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.29it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.31it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.31it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.45it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.33it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.64s/it]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.29it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.29it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.43it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.30it/s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.66s/it]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.29it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.32it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.28it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.44it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.29it/s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.71s/it]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.36it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.25it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.35it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.30it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.35it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.28it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.28it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.35it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.30it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.28it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.35it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.29it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.31it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.27it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.33it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.31it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.29it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.36it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.21it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.29it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.25it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.53it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.40it/s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.57s/it]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.31it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.23it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.29it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.35it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.28it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.22it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.40it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.35it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.42it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.24it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.28it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.27it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.35it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.33it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.27it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.34it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.19it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.25it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.33it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.23it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.28it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.43it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.35it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.62s/it]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.26it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.33it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.26it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.42it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.29it/s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.66s/it]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.33it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.24it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.37it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.27it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.46it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.29it/s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:14<00:14,  4.69s/it]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.24it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.37it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.33it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.26it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.35it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.30it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.34it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.34it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.32it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.26it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.34it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.32it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.26it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.34it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.33it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.36it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.54it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.40it/s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.56s/it]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.27it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.33it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.25it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.31it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.42it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.31it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.39it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.24it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.29it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.37it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.20it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.28it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.31it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.22it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.33it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.38it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.20it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.21it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.38it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.23it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.33it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.30it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.25it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.22it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.30it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:04<00:00,  4.21it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.30it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.46it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.33it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.62s/it]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.31it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.21it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.29it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.31it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.20it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.34it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.25it/s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.68s/it]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.31it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.30it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.34it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.30it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.46it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.33it/s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.66s/it]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.35it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.38it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.13it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.32it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.18it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.34it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.30it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.24it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.21it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.28it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.34it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.30it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.30it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.21it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.34it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.30it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.17it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.34it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.30it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.21it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.29it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.36it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.51it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.37it/s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.57s/it]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.30it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.22it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.33it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.22it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.29it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.23it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.35it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.29it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.37it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.23it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.24it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.20it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.26it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.21it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.38it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.25it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.34it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.24it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.12it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.27it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.18it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.25it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.29it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.22it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.33it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.27it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:04<00:00,  4.24it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.24it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.42it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.32it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:23<00:04,  4.62s/it]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.24it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.29it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.26it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.43it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.26it/s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:23<00:04,  4.68s/it]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.34it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.24it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.29it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.27it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.28it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.45it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.30it/s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:23<00:04,  4.66s/it]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.19it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.25it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.20it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.27it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.28it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.16it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.34it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.30it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.28it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.32it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.16it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.31it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.23it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.28it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.22it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.31it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.23it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.16it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.31it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.20it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.32it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.47it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.33it/s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:22<00:04,  4.59s/it]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.22it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.26it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.26it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.32it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.31it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.30it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.24it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.20it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.28it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.26it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.23it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.25it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.17it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.30it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.24it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.20it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.25it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.33it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.24it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.27it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.20it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.27it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.28it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.23it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.24it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.29it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.18it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:04<00:00,  4.28it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.21it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.33it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.25it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.19it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.30it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.25it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:04<00:00,  4.19it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.29it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.47it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.28it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.64s/it]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.63s/it]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:45 - INFO - transformers.trainer -
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:45 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:45 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.33it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.20it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:04<00:00,  4.25it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.17it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.31it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.25it/s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:28<00:00,  4.69s/it]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:28<00:00,  4.68s/it]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:46 - INFO - transformers.trainer -
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:46 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:46 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.26it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.27it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.45it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.28it/s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:28<00:00,  4.66s/it]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:28<00:00,  4.68s/it]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:46 - INFO - transformers.trainer -
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:46 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:46 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:46 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.34it/s][A
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:46 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:46 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:46 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:46 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Evaluation:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:00<00:00, 49.73it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 49.72it/s]
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:46 - INFO - transformers.trainer -   {'eval_loss': 0.6928180588616265, 'eval_acc': 0.5633802816901409, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:46 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:46 - INFO - __main__ -     eval_loss = 0.6928180588616265
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:46 - INFO - __main__ -     eval_acc = 0.5633802816901409
[2m[36m(Process_task pid=690, ip=10.130.64.122)[0m 07/05/2022 16:02:46 - INFO - __main__ -     epoch = 6.0
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:46 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.33it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:47 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:47 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:47 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:47 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:47 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.30it/s][A
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Evaluation:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:00<00:00, 49.93it/s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 49.75it/s]
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:47 - INFO - transformers.trainer -   {'eval_loss': 0.6902288595835367, 'eval_acc': 0.5633802816901409, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:47 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:47 - INFO - __main__ -     eval_loss = 0.6902288595835367
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:47 - INFO - __main__ -     eval_acc = 0.5633802816901409
[2m[36m(Process_task pid=688, ip=10.131.66.16)[0m 07/05/2022 16:02:47 - INFO - __main__ -     epoch = 6.0
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:47 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:47 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:47 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:47 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.33it/s][A
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:00<00:00, 50.05it/s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 46.37it/s]
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:47 - INFO - transformers.trainer -   {'eval_loss': 0.6930272446738349, 'eval_acc': 0.4788732394366197, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:47 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:47 - INFO - __main__ -     eval_loss = 0.6930272446738349
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:47 - INFO - __main__ -     eval_acc = 0.4788732394366197
[2m[36m(Process_task pid=800, ip=10.128.66.16)[0m 07/05/2022 16:02:47 - INFO - __main__ -     epoch = 6.0
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.34it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.31it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.44it/s][A
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.34it/s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.59s/it]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.58s/it]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:47 - INFO - transformers.trainer -
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:47 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:47 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32/config.json
2022-07-05 16:02:48 roberta-base lr-2e-5 WNLI seed-40 took 44.2s on mycluster-ray-worker-type-9h8mt ... 1 of 4 subtasks done
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:48 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32/pytorch_model.bin
2022-07-05 16:02:48 roberta-base lr-2e-5 WNLI seed-41 took 44.5s on mycluster-ray-worker-type-lncm6 ... 2 of 4 subtasks done
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:48 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:48 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:48 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:48 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Evaluation:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:00<00:00, 48.45it/s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 49.66it/s]
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:49 - INFO - transformers.trainer -   {'eval_loss': 0.6969749132792155, 'eval_acc': 0.38028169014084506, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:49 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:49 - INFO - __main__ -     eval_loss = 0.6969749132792155
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:49 - INFO - __main__ -     eval_acc = 0.38028169014084506
[2m[36m(Process_task pid=797, ip=10.130.66.15)[0m 07/05/2022 16:02:49 - INFO - __main__ -     epoch = 6.0
2022-07-05 16:02:49 roberta-base lr-2e-5 WNLI seed-43 took 45.5s on mycluster-ray-worker-type-lwbrv ... 3 of 4 subtasks done
2022-07-05 16:02:50 roberta-base lr-2e-5 WNLI seed-42 took 44.7s on mycluster-ray-worker-type-lt59j ... 4 of 4 subtasks done
