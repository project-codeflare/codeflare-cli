
2022-07-18 09:59:06 Starting Glue benchmark ---------------
model: roberta-base
gluedata: glue_data
bucket: browsey
tasks: WNLI
seeds: 40 41 42 43
learning_rate: 2e-05
savemodel: True
ray_service: glue-cluster-ray-head:10001
S3 data looks good in bucket=browsey
  actor=DataRefsActor not found ... deploy it
2022-07-18 09:59:09 Get glue_data data reference from data actor
[2m[36m(DataRefs pid=563)[0m   Data: try remote get glue_data from s3
[2m[36m(DataRefs pid=563)[0m   Data: done remote get glue_data from s3
[2m[36m(DataRefs pid=563)[0m   Data: try cache put glue_data into plasma
2022-07-18 09:59:14 Get roberta-base data reference from data actor
[2m[36m(DataRefs pid=563)[0m   Data: done cache put glue_data data into plasma
[2m[36m(DataRefs pid=563)[0m   Data: try remote get roberta-base from s3
[2m[36m(DataRefs pid=563)[0m   Data: done remote get roberta-base from s3
[2m[36m(DataRefs pid=563)[0m   Data: try cache put roberta-base into plasma
[2m[36m(DataRefs pid=563)[0m   Data: done cache put roberta-base data into plasma
2022-07-18 09:59:35 Submitted 4 subtasks
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Node ID: NodeID(6584047824f82630e8aba879efa2c3bde483868976b7e9dc48a6e31c)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m GPU IDs: [0]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 09:59:36 Get glue_data data reference from data actor
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 09:59:36 Data: try cache get glue_data
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Node ID: NodeID(51cf60f478398e2f968e25e6caa1c3a7d772f65e7067fd8004e619a9)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m GPU IDs: [0]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 09:59:37 Get glue_data data reference from data actor
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 09:59:37 Data: try cache get glue_data
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Node ID: NodeID(57b748f982c69aa413c0b49ffd1520c1105e13b6737e273df923d22a)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m GPU IDs: [0]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 09:59:37 Get glue_data data reference from data actor
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 09:59:37 Data: try cache get glue_data
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Node ID: NodeID(5a32dc12c9be3df7931316035d47dcd18fe77bfad5879cce55c0682b)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m GPU IDs: [0]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 09:59:37 Get glue_data data reference from data actor
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 09:59:37 Data: try cache get glue_data
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 09:59:39 Data: done cache get glue_data length=405875765 took 2.04s
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 09:59:39 Data: try unpack glue_data tarfile
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 09:59:39 Data: done cache get glue_data length=405875765 took 2.39s
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 09:59:39 Data: try unpack glue_data tarfile
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 09:59:39 Data: done cache get glue_data length=405875765 took 2.76s
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 09:59:39 Data: try unpack glue_data tarfile
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 09:59:40 Data: done cache get glue_data length=405875765 took 3.09s
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 09:59:40 Data: try unpack glue_data tarfile
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 09:59:51 Data: done unpack glue_data tarfile took 11.80s
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 09:59:51 Get roberta-base data reference from data actor
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 09:59:51 Data: try cache get roberta-base
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 09:59:51 Data: done unpack glue_data tarfile took 12.11s
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 09:59:51 Get roberta-base data reference from data actor
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 09:59:51 Data: try cache get roberta-base
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 09:59:51 Data: done unpack glue_data tarfile took 11.95s
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 09:59:51 Get roberta-base data reference from data actor
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 09:59:51 Data: try cache get roberta-base
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 09:59:52 Data: done unpack glue_data tarfile took 12.18s
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 09:59:52 Get roberta-base data reference from data actor
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 09:59:52 Data: try cache get roberta-base
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 09:59:56 Data: done cache get roberta-base length=1371970574 took 5.32s
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 09:59:56 Data: try unpack roberta-base tarfile
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 09:59:58 Data: done cache get roberta-base length=1371970574 took 6.83s
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 09:59:58 Data: try unpack roberta-base tarfile
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 09:59:59 Data: done cache get roberta-base length=1371970574 took 7.67s
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 10:00:00 Data: done cache get roberta-base length=1371970574 took 7.53s
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 09:59:59 Data: try unpack roberta-base tarfile
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 10:00:00 Data: try unpack roberta-base tarfile
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 10:00:23 Data: done unpack roberta-base tarfile took 26.22s
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Processing task WNLI seed 40 with model roberta-base
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m --2022-07-18 10:00:23--  https://raw.githubusercontent.com/huggingface/transformers/b0892fa0e8df02d683e05e625b3903209bff362d/examples/text-classification/run_glue.py
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m HTTP request sent, awaiting response... 
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 200 OK
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Length: 9504 (9.3K) [text/plain]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Saving to: â€˜run_glue.pyâ€™
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m      0K .........                                             100% 68.4M=0s
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 2022-07-18 10:00:23 (68.4 MB/s) - â€˜run_glue.pyâ€™ saved [9504/9504]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 10:00:25 Data: done unpack roberta-base tarfile took 26.53s
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Processing task WNLI seed 43 with model roberta-base
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m --2022-07-18 10:00:25--  https://raw.githubusercontent.com/huggingface/transformers/b0892fa0e8df02d683e05e625b3903209bff362d/examples/text-classification/run_glue.py
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m HTTP request sent, awaiting response... 200 OK
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Length: 9504 (9.3K) [text/plain]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Saving to: â€˜run_glue.pyâ€™
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m      0K .........                                             100% 64.4M=0s
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 2022-07-18 10:00:25 (64.4 MB/s) - â€˜run_glue.pyâ€™ saved [9504/9504]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 10:00:27 Data: done unpack roberta-base tarfile took 26.69s
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Processing task WNLI seed 41 with model roberta-base
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m --2022-07-18 10:00:27--  https://raw.githubusercontent.com/huggingface/transformers/b0892fa0e8df02d683e05e625b3903209bff362d/examples/text-classification/run_glue.py
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... 
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m connected.
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m HTTP request sent, awaiting response... 200 OK
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Length: 9504 (9.3K) [text/plain]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Saving to: â€˜run_glue.pyâ€™
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m      0K .........                                             100% 68.7M=0s
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 2022-07-18 10:00:27 (68.7 MB/s) - â€˜run_glue.pyâ€™ saved [9504/9504]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 10:00:27 Data: done unpack roberta-base tarfile took 26.56s
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Processing task WNLI seed 42 with model roberta-base
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m --2022-07-18 10:00:27--  https://raw.githubusercontent.com/huggingface/transformers/b0892fa0e8df02d683e05e625b3903209bff362d/examples/text-classification/run_glue.py
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m HTTP request sent, awaiting response... 200 OK
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Length: 9504 (9.3K) [text/plain]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Saving to: â€˜run_glue.pyâ€™
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m      0K .........                                             100% 72.3M=0s
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 2022-07-18 10:00:27 (72.3 MB/s) - â€˜run_glue.pyâ€™ saved [9504/9504]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul18_10-00-27_mycluster-ray-worker-type-vbblg', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=40, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "architectures": [
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   ],
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m }
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "architectures": [
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   ],
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m }
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /tmp/cache/tmpu9vs0ufw
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899k/899k [00:00<00:00, 43.2MB/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.file_utils -   creating metadata file for /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /tmp/cache/tmpokj0danp
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 42.2MB/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.file_utils -   creating metadata file for /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:27 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:28 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul18_10-00-30_mycluster-ray-worker-type-htgd6', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=43, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "architectures": [
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   ],
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m }
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "architectures": [
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   ],
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m }
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /tmp/cache/tmpwly7u356
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899k/899k [00:00<00:00, 38.7MB/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.file_utils -   creating metadata file for /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /tmp/cache/tmpeoox8l_r
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 12.1MB/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.file_utils -   creating metadata file for /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:30 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul18_10-00-31_mycluster-ray-worker-type-vf2n9', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=41, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "architectures": [
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   ],
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m }
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "architectures": [
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   ],
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m }
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /tmp/cache/tmp3y7ede2p
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899k/899k [00:00<00:00, 45.0MB/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   creating metadata file for /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /tmp/cache/tmp5qghimr2
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 39.9MB/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   creating metadata file for /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul18_10-00-31_mycluster-ray-worker-type-nwq8q', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "architectures": [
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   ],
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m }
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "architectures": [
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   ],
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m }
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:31 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /tmp/cache/tmpap_vum2u
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899k/899k [00:00<00:00, 44.1MB/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   creating metadata file for /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /tmp/cache/tmpy42opgjk
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 21.7MB/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.file_utils -   creating metadata file for /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:31 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   guid: train-0
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 100, 4889, 10, 7756, 149, 10, 33129, 4, 520, 38, 2468, 5, 7756, 66, 6, 24, 56, 10, 4683, 4, 2, 2, 133, 33129, 56, 10, 4683, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   guid: train-1
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 10567, 1705, 75, 192, 5, 1289, 19, 7835, 11, 760, 9, 123, 142, 37, 16, 98, 765, 4, 2, 2, 10567, 16, 98, 765, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   guid: train-2
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 249, 1128, 70, 9, 5, 5188, 453, 4, 252, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 2, 133, 249, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   guid: train-3
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 21976, 3905, 7734, 18, 1246, 11, 960, 4, 91, 16882, 123, 13481, 4, 2, 2, 21976, 16882, 123, 13481, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   guid: train-4
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 1779, 17734, 219, 1113, 1348, 5, 11657, 6, 69, 985, 21, 8416, 4, 264, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 2, 19456, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.066 s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   guid: dev-0
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 15160, 16, 3741, 29519, 19, 2549, 4, 85, 34, 7, 28, 17317, 4, 2, 2, 133, 2549, 34, 7, 28, 17317, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   guid: dev-1
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 35903, 6536, 15, 6470, 18, 1883, 53, 79, 222, 45, 1948, 4, 2, 2, 38621, 222, 45, 1948, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   guid: dev-2
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 387, 4774, 399, 75, 120, 5800, 19, 15282, 6, 54, 56, 847, 69, 160, 6, 142, 79, 2294, 8, 11590, 7, 2724, 4, 2, 2, 104, 2368, 2294, 8, 11590, 7, 2724, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   guid: dev-3
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 3084, 65, 9447, 622, 7, 28, 5074, 8, 20100, 4, 125, 10, 92, 892, 31, 5, 589, 9, 4222, 19902, 1655, 5839, 10648, 14, 14, 18, 2230, 141, 24, 817, 201, 619, 4, 2, 2, 1711, 18, 2230, 141, 622, 817, 201, 619, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   guid: dev-4
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 313, 1705, 75, 5258, 39, 979, 142, 37, 21, 98, 2016, 4, 2, 2, 133, 979, 21, 98, 2016, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:33 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.008 s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   guid: train-0
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 100, 4889, 10, 7756, 149, 10, 33129, 4, 520, 38, 2468, 5, 7756, 66, 6, 24, 56, 10, 4683, 4, 2, 2, 133, 33129, 56, 10, 4683, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   guid: train-1
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 10567, 1705, 75, 192, 5, 1289, 19, 7835, 11, 760, 9, 123, 142, 37, 16, 98, 765, 4, 2, 2, 10567, 16, 98, 765, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   guid: train-2
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 249, 1128, 70, 9, 5, 5188, 453, 4, 252, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 2, 133, 249, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   guid: train-3
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 21976, 3905, 7734, 18, 1246, 11, 960, 4, 91, 16882, 123, 13481, 4, 2, 2, 21976, 16882, 123, 13481, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   guid: train-4
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:35 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 1779, 17734, 219, 1113, 1348, 5, 11657, 6, 69, 985, 21, 8416, 4, 264, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 2, 19456, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.063 s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   guid: dev-0
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 15160, 16, 3741, 29519, 19, 2549, 4, 85, 34, 7, 28, 17317, 4, 2, 2, 133, 2549, 34, 7, 28, 17317, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   guid: dev-1
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 35903, 6536, 15, 6470, 18, 1883, 53, 79, 222, 45, 1948, 4, 2, 2, 38621, 222, 45, 1948, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   guid: dev-2
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 387, 4774, 399, 75, 120, 5800, 19, 15282, 6, 54, 56, 847, 69, 160, 6, 142, 79, 2294, 8, 11590, 7, 2724, 4, 2, 2, 104, 2368, 2294, 8, 11590, 7, 2724, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   guid: dev-3
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 3084, 65, 9447, 622, 7, 28, 5074, 8, 20100, 4, 125, 10, 92, 892, 31, 5, 589, 9, 4222, 19902, 1655, 5839, 10648, 14, 14, 18, 2230, 141, 24, 817, 201, 619, 4, 2, 2, 1711, 18, 2230, 141, 622, 817, 201, 619, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   guid: dev-4
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 313, 1705, 75, 5258, 39, 979, 142, 37, 21, 98, 2016, 4, 2, 2, 133, 979, 21, 98, 2016, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:36 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.011 s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:36 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:36 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:36 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   guid: train-0
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 100, 4889, 10, 7756, 149, 10, 33129, 4, 520, 38, 2468, 5, 7756, 66, 6, 24, 56, 10, 4683, 4, 2, 2, 133, 33129, 56, 10, 4683, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   guid: train-1
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 10567, 1705, 75, 192, 5, 1289, 19, 7835, 11, 760, 9, 123, 142, 37, 16, 98, 765, 4, 2, 2, 10567, 16, 98, 765, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   guid: train-2
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 249, 1128, 70, 9, 5, 5188, 453, 4, 252, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 2, 133, 249, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   guid: train-3
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 21976, 3905, 7734, 18, 1246, 11, 960, 4, 91, 16882, 123, 13481, 4, 2, 2, 21976, 16882, 123, 13481, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   guid: train-4
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:36 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 1779, 17734, 219, 1113, 1348, 5, 11657, 6, 69, 985, 21, 8416, 4, 264, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 2, 19456, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.077 s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: dev-0
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 15160, 16, 3741, 29519, 19, 2549, 4, 85, 34, 7, 28, 17317, 4, 2, 2, 133, 2549, 34, 7, 28, 17317, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: dev-1
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 35903, 6536, 15, 6470, 18, 1883, 53, 79, 222, 45, 1948, 4, 2, 2, 38621, 222, 45, 1948, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: dev-2
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 387, 4774, 399, 75, 120, 5800, 19, 15282, 6, 54, 56, 847, 69, 160, 6, 142, 79, 2294, 8, 11590, 7, 2724, 4, 2, 2, 104, 2368, 2294, 8, 11590, 7, 2724, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: dev-3
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 3084, 65, 9447, 622, 7, 28, 5074, 8, 20100, 4, 125, 10, 92, 892, 31, 5, 589, 9, 4222, 19902, 1655, 5839, 10648, 14, 14, 18, 2230, 141, 24, 817, 201, 619, 4, 2, 2, 1711, 18, 2230, 141, 622, 817, 201, 619, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: dev-4
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 313, 1705, 75, 5258, 39, 979, 142, 37, 21, 98, 2016, 4, 2, 2, 133, 979, 21, 98, 2016, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:37 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.007 s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: train-0
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 100, 4889, 10, 7756, 149, 10, 33129, 4, 520, 38, 2468, 5, 7756, 66, 6, 24, 56, 10, 4683, 4, 2, 2, 133, 33129, 56, 10, 4683, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: train-1
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 10567, 1705, 75, 192, 5, 1289, 19, 7835, 11, 760, 9, 123, 142, 37, 16, 98, 765, 4, 2, 2, 10567, 16, 98, 765, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: train-2
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 249, 1128, 70, 9, 5, 5188, 453, 4, 252, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 2, 133, 249, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: train-3
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 21976, 3905, 7734, 18, 1246, 11, 960, 4, 91, 16882, 123, 13481, 4, 2, 2, 21976, 16882, 123, 13481, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: train-4
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 1779, 17734, 219, 1113, 1348, 5, 11657, 6, 69, 985, 21, 8416, 4, 264, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 2, 19456, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.062 s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: dev-0
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 15160, 16, 3741, 29519, 19, 2549, 4, 85, 34, 7, 28, 17317, 4, 2, 2, 133, 2549, 34, 7, 28, 17317, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: dev-1
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 35903, 6536, 15, 6470, 18, 1883, 53, 79, 222, 45, 1948, 4, 2, 2, 38621, 222, 45, 1948, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: dev-2
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 387, 4774, 399, 75, 120, 5800, 19, 15282, 6, 54, 56, 847, 69, 160, 6, 142, 79, 2294, 8, 11590, 7, 2724, 4, 2, 2, 104, 2368, 2294, 8, 11590, 7, 2724, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: dev-3
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 3084, 65, 9447, 622, 7, 28, 5074, 8, 20100, 4, 125, 10, 92, 892, 31, 5, 589, 9, 4222, 19902, 1655, 5839, 10648, 14, 14, 18, 2230, 141, 24, 817, 201, 619, 4, 2, 2, 1711, 18, 2230, 141, 622, 817, 201, 619, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   guid: dev-4
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 313, 1705, 75, 5258, 39, 979, 142, 37, 21, 98, 2016, 4, 2, 2, 133, 979, 21, 98, 2016, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:37 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.007 s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:37 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:37 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:37 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:37 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:37 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:37 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:37 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:37 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:00:37 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:05,  3.75it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.05it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.19it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.26it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.28it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.27it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:40 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:40 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:40 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:40 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:40 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:40 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:40 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:40 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:00:40 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.28it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.25it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  3.81it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.25it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.09it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.27it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.21it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.27it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:00:41 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:05,  3.76it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.29it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  3.86it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.04it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.16it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.19it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.25it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.29it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.30it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.45it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.29it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:23,  4.66s/it]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.26it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.20it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.30it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.33it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.29it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.33it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.41it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.56it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.37it/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:22,  4.58s/it]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.20it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.32it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.57it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.35it/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:22,  4.60s/it]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.56it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.39it/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:22,  4.56s/it]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.16it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.30it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.32it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.44it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.29it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.29it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.33it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.32it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.64s/it]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.27it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.27it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.33it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.27it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.59it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.42it/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.55s/it]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.27it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.45it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.46it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.45it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.55it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.39it/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.57s/it]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.54it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.39it/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.56s/it]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.27it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.26it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.42it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.28it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.41it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.42it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.30it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.47it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.32it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.64s/it]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.42it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.43it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.42it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.21it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.41it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.42it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.41it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.42it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.23it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.27it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.28it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.41it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.58it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.43it/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.53s/it]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.28it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.28it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.41it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.43it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.58it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.43it/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.55s/it]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.44it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.28it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.34it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.51it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.41it/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.55s/it]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.28it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.42it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.30it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.27it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.44it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.43it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.45it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.27it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.19it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.21it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.44it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.25it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.42it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.30it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.64s/it]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.41it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.27it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.41it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.30it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.44it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.41it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.45it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.45it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.44it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.26it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.52it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.45it/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.52s/it]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.30it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.46it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.27it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.44it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.53it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.39it/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.55s/it]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.43it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.55it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.41it/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.54s/it]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.43it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.32it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.32it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:23<00:04,  4.64s/it]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.29it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.41it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.33it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.43it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.43it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.28it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.42it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.29it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.30it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.56it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.42it/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:22<00:04,  4.52s/it]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.30it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.46it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.28it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.57it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.41it/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:22<00:04,  4.55s/it]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.32it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.55it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.42it/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:22<00:04,  4.54s/it]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.33it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.34it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.31it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.51it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.36it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.62s/it]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.63s/it]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:05 - INFO - transformers.trainer -
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:05 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:05 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.40it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.41it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:06 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:06 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:06 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:06 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:06 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Evaluation:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:00<00:00, 49.91it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 49.53it/s]
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:06 - INFO - transformers.trainer -   {'eval_loss': 0.6928180588616265, 'eval_acc': 0.5633802816901409, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:06 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:06 - INFO - __main__ -     eval_loss = 0.6928180588616265
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:06 - INFO - __main__ -     eval_acc = 0.5633802816901409
[2m[36m(Process_task pid=329, ip=10.130.86.15)[0m 07/18/2022 10:01:06 - INFO - __main__ -     epoch = 6.0
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.35it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.58it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.41it/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.52s/it]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.53s/it]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:07 - INFO - transformers.trainer -
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:07 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:07 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.36it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:08 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:08 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:08 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:08 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:08 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
2022-07-18 10:01:08 roberta-base lr-2e-5 WNLI seed-40 took 44.2s on mycluster-ray-worker-type-vbblg ... 1 of 4 subtasks done
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.54it/s][A
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.40it/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.55s/it]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.55s/it]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:08 - INFO - transformers.trainer -
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:08 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:08 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:00<00:00, 50.38it/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 51.25it/s]
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:08 - INFO - transformers.trainer -   {'eval_loss': 0.6930272446738349, 'eval_acc': 0.4788732394366197, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:08 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:08 - INFO - __main__ -     eval_loss = 0.6930272446738349
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:08 - INFO - __main__ -     eval_acc = 0.4788732394366197
[2m[36m(Process_task pid=330, ip=10.131.84.17)[0m 07/18/2022 10:01:08 - INFO - __main__ -     epoch = 6.0
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.26it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.47it/s][A
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.39it/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.54s/it]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.55s/it]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:08 - INFO - transformers.trainer -
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:08 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:08 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:09 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:09 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:09 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:09 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:09 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:09 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:09 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:09 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:09 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:09 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:00<00:00, 50.77it/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 50.68it/s]
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:09 - INFO - transformers.trainer -   {'eval_loss': 0.6902288595835367, 'eval_acc': 0.5633802816901409, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:09 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:09 - INFO - __main__ -     eval_loss = 0.6902288595835367
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:09 - INFO - __main__ -     eval_acc = 0.5633802816901409
[2m[36m(Process_task pid=330, ip=10.128.86.42)[0m 07/18/2022 10:01:09 - INFO - __main__ -     epoch = 6.0
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:00<00:00, 50.64it/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 51.22it/s]
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:09 - INFO - transformers.trainer -   {'eval_loss': 0.6969749132792155, 'eval_acc': 0.38028169014084506, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:09 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:09 - INFO - __main__ -     eval_loss = 0.6969749132792155
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:09 - INFO - __main__ -     eval_acc = 0.38028169014084506
[2m[36m(Process_task pid=329, ip=10.129.86.14)[0m 07/18/2022 10:01:09 - INFO - __main__ -     epoch = 6.0
2022-07-18 10:01:10   eval=0.5633802816901409, model pull took 1.9s for length=501032683
2022-07-18 10:01:10 roberta-base lr-2e-5 WNLI seed-43 took 43.6s on mycluster-ray-worker-type-htgd6 ... 2 of 4 subtasks done
2022-07-18 10:01:11 roberta-base lr-2e-5 WNLI seed-41 took 43.5s on mycluster-ray-worker-type-vf2n9 ... 3 of 4 subtasks done
2022-07-18 10:01:11 roberta-base lr-2e-5 WNLI seed-42 took 43.2s on mycluster-ray-worker-type-nwq8q ... 4 of 4 subtasks done
