
2022-06-17 07:06:04 Starting Glue benchmark ---------------
model: roberta-base
gluedata: glue_data
bucket: browsey
tasks: WNLI
seeds: 40 41 42 43
learning_rate: 2e-05
savemodel: True
ray_service: glue-cluster-ray-head:10001
S3 data looks good in bucket=browsey
 Found actor=DataRefsActor with state {'glue_data': 'Cached', 'roberta-base': 'Cached'}
2022-06-17 07:06:04 Submitted 4 subtasks
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Node ID: NodeID(9ce425f4bcb47a101b6b27ae50d84c006345305007f88a3c06936d98)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m GPU IDs: [0]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 2022-06-17 07:06:06 Get glue_data data reference from data actor
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 2022-06-17 07:06:06 getting data length=405875765 took 0.19s
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 2022-06-17 07:06:18 unpacking glue_data tarfile took 11.90s
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 2022-06-17 07:06:18 Get roberta-base data reference from data actor
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 2022-06-17 07:06:19 getting data length=1371970574 took 0.63s
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 2022-06-17 07:06:59 unpacking roberta-base tarfile took 38.83s
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Processing task WNLI seed 40 with model roberta-base
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m --2022-06-17 07:06:59--  https://raw.githubusercontent.com/huggingface/transformers/b0892fa0e8df02d683e05e625b3903209bff362d/examples/text-classification/run_glue.py
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m HTTP request sent, awaiting response... 
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 200 OK
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Length: 9504 (9.3K) [text/plain]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Saving to: â€˜run_glue.pyâ€™
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m      0K .........                                             100% 64.9M=0s
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 2022-06-17 07:06:59 (64.9 MB/s) - â€˜run_glue.pyâ€™ saved [9504/9504]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:03 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:03 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:03 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jun17_07-07-03_mycluster-ray-worker-type-78bjh', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=40, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:03 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:03 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "architectures": [
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   ],
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m }
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:03 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:03 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "architectures": [
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   ],
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m }
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:03 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:03 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:03 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   guid: train-0
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 100, 4889, 10, 7756, 149, 10, 33129, 4, 520, 38, 2468, 5, 7756, 66, 6, 24, 56, 10, 4683, 4, 2, 2, 133, 33129, 56, 10, 4683, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   guid: train-1
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 10567, 1705, 75, 192, 5, 1289, 19, 7835, 11, 760, 9, 123, 142, 37, 16, 98, 765, 4, 2, 2, 10567, 16, 98, 765, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   guid: train-2
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 249, 1128, 70, 9, 5, 5188, 453, 4, 252, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 2, 133, 249, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   guid: train-3
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 21976, 3905, 7734, 18, 1246, 11, 960, 4, 91, 16882, 123, 13481, 4, 2, 2, 21976, 16882, 123, 13481, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   guid: train-4
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:08 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 1779, 17734, 219, 1113, 1348, 5, 11657, 6, 69, 985, 21, 8416, 4, 264, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 2, 19456, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.064 s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   guid: dev-0
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 15160, 16, 3741, 29519, 19, 2549, 4, 85, 34, 7, 28, 17317, 4, 2, 2, 133, 2549, 34, 7, 28, 17317, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   guid: dev-1
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 35903, 6536, 15, 6470, 18, 1883, 53, 79, 222, 45, 1948, 4, 2, 2, 38621, 222, 45, 1948, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   guid: dev-2
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 387, 4774, 399, 75, 120, 5800, 19, 15282, 6, 54, 56, 847, 69, 160, 6, 142, 79, 2294, 8, 11590, 7, 2724, 4, 2, 2, 104, 2368, 2294, 8, 11590, 7, 2724, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   guid: dev-3
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 3084, 65, 9447, 622, 7, 28, 5074, 8, 20100, 4, 125, 10, 92, 892, 31, 5, 589, 9, 4222, 19902, 1655, 5839, 10648, 14, 14, 18, 2230, 141, 24, 817, 201, 619, 4, 2, 2, 1711, 18, 2230, 141, 622, 817, 201, 619, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   *** Example ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   guid: dev-4
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 313, 1705, 75, 5258, 39, 979, 142, 37, 21, 98, 2016, 4, 2, 2, 133, 979, 21, 98, 2016, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:09 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.007 s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:13 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:13 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:13 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:13 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:13 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:13 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:13 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:13 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:13 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:05,  3.75it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.05it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.20it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.27it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.30it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.53it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.37it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:22,  4.58s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.52it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.40it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.56s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.44it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.42it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.31it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.54it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.41it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.55s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.42it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.31it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.52it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.39it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.55s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.44it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.38it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:22<00:04,  4.56s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.53it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.40it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.55s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.55s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:41 - INFO - transformers.trainer -
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:41 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:41 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:41 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:42 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:42 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:42 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:42 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:00<00:00, 51.13it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 51.57it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:42 - INFO - transformers.trainer -   {'eval_loss': 0.6928180588616265, 'eval_acc': 0.5633802816901409, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:42 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:42 - INFO - __main__ -     eval_loss = 0.6928180588616265
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:42 - INFO - __main__ -     eval_acc = 0.5633802816901409
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:42 - INFO - __main__ -     epoch = 6.0
2022-06-17 07:07:43 roberta-base lr-2e-5 WNLI seed-40 took 43.7s on mycluster-ray-worker-type-78bjh ... 1 of 4 subtasks done
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Node ID: NodeID(9ce425f4bcb47a101b6b27ae50d84c006345305007f88a3c06936d98)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m GPU IDs: [0]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Reusing previous existing glue-dataset
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Reusing roberta-base directory
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Processing task WNLI seed 41 with model roberta-base
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:47 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:47 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:47 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jun17_07-07-47_mycluster-ray-worker-type-78bjh', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=41, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:47 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:47 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "architectures": [
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   ],
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m }
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:47 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:47 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "architectures": [
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   ],
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m }
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:47 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:47 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:47 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:52 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:52 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:52 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.040 s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:52 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.005 s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:57 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:57 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:57 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:57 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:57 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:57 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:57 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:57 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:07:57 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  3.81it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.12it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.24it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.30it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.51it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.36it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:22,  4.59s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.30it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.49it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.38it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.58s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.28it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.24it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.30it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.55it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.39it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.57s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.42it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.43it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.53it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.40it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.56s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.26it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.29it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.30it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.31it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.30it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.23it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.43it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.35it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:22<00:04,  4.57s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.26it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.29it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.31it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.46it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.36it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.58s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.57s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:24 - INFO - transformers.trainer -
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:24 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:24 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:25 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:25 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:25 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:25 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:25 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:00<00:00, 51.06it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 51.54it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:25 - INFO - transformers.trainer -   {'eval_loss': 0.6902288595835367, 'eval_acc': 0.5633802816901409, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:25 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:25 - INFO - __main__ -     eval_loss = 0.6902288595835367
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:25 - INFO - __main__ -     eval_acc = 0.5633802816901409
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:25 - INFO - __main__ -     epoch = 6.0
2022-06-17 07:08:27 roberta-base lr-2e-5 WNLI seed-41 took 42.9s on mycluster-ray-worker-type-78bjh ... 2 of 4 subtasks done
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Node ID: NodeID(9ce425f4bcb47a101b6b27ae50d84c006345305007f88a3c06936d98)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m GPU IDs: [0]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Reusing previous existing glue-dataset
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Reusing roberta-base directory
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Processing task WNLI seed 42 with model roberta-base
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:31 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:31 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:31 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jun17_07-08-31_mycluster-ray-worker-type-78bjh', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:31 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:31 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "architectures": [
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   ],
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m }
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:31 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:31 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "architectures": [
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   ],
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m }
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:31 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:31 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:31 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:36 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:36 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:36 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.036 s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:36 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.004 s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:40 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:40 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:40 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:40 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:40 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:40 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:40 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:40 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:08:40 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:05,  3.69it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.03it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.18it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.23it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.28it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.28it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.31it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.54it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.35it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:23,  4.60s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.52it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.39it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.57s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.31it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.53it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.38it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.57s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.42it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.25it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.30it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.53it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.38it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.57s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.23it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.31it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.53it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.40it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:22<00:04,  4.56s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.25it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.29it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.30it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.52it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.37it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.56s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.57s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:08 - INFO - transformers.trainer -
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:08 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:08 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:09 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:09 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:09 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:09 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:09 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:00<00:00, 49.32it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 48.78it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:09 - INFO - transformers.trainer -   {'eval_loss': 0.6969749132792155, 'eval_acc': 0.38028169014084506, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:09 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:09 - INFO - __main__ -     eval_loss = 0.6969749132792155
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:09 - INFO - __main__ -     eval_acc = 0.38028169014084506
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:09 - INFO - __main__ -     epoch = 6.0
2022-06-17 07:09:10 roberta-base lr-2e-5 WNLI seed-42 took 43.2s on mycluster-ray-worker-type-78bjh ... 3 of 4 subtasks done
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Node ID: NodeID(9ce425f4bcb47a101b6b27ae50d84c006345305007f88a3c06936d98)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m GPU IDs: [0]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Reusing previous existing glue-dataset
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Reusing roberta-base directory
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Processing task WNLI seed 43 with model roberta-base
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:14 - INFO - transformers.training_args -   PyTorch: setting up devices
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:15 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:15 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jun17_07-09-14_mycluster-ray-worker-type-78bjh', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=43, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:15 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:15 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "architectures": [
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   ],
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "finetuning_task": "wnli",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m }
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:15 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:15 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "architectures": [
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m     "RobertaForMaskedLM"
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   ],
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "attention_probs_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "bos_token_id": 0,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "eos_token_id": 2,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "gradient_checkpointing": false,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_act": "gelu",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_dropout_prob": 0.1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "hidden_size": 768,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "initializer_range": 0.02,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "intermediate_size": 3072,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "layer_norm_eps": 1e-05,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "max_position_embeddings": 514,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "model_type": "roberta",
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_attention_heads": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "num_hidden_layers": 12,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "pad_token_id": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "type_vocab_size": 1,
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m   "vocab_size": 50265
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m }
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:15 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:15 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:15 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:20 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:20 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:20 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.036 s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:20 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.004 s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:24 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:24 - INFO - transformers.trainer -   ***** Running training *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:24 - INFO - transformers.trainer -     Num examples = 635
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:24 - INFO - transformers.trainer -     Num Epochs = 6
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:24 - INFO - transformers.trainer -     Instantaneous batch size per device = 32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:24 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:24 - INFO - transformers.trainer -     Gradient Accumulation steps = 1
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:24 - INFO - transformers.trainer -     Total optimization steps = 120
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:24 - INFO - transformers.trainer -     Starting fine-tuning.
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:05,  3.70it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.04it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.18it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.25it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.28it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.32it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.48it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.34it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  17%|â–ˆâ–‹        | 1/6 [00:04<00:23,  4.61s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.42it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.54it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.40it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:09<00:18,  4.57s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.43it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.44it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.42it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.58it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.42it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:13<00:13,  4.55s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.42it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.33it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.31it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.22it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.28it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.31it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.50it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.39it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:18<00:09,  4.55s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.45it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.34it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.53it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.40it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:22<00:04,  4.55s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:   5%|â–Œ         | 1/20 [00:00<00:04,  4.45it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  20%|â–ˆâ–ˆ        | 4/20 [00:00<00:03,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.42it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:01<00:03,  4.41it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:03,  4.31it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.36it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.35it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  4.37it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.38it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:02<00:01,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:03<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:04<00:00,  4.39it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  4.40it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.57it/s][A
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.41it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.54s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:27<00:00,  4.55s/it]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:51 - INFO - transformers.trainer -
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Training completed. Do not forget to share your model on huggingface.co/models =)
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:51 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:51 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32/config.json
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:52 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32/pytorch_model.bin
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:52 - INFO - __main__ -   *** Evaluate ***
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:52 - INFO - transformers.trainer -   ***** Running Evaluation *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:52 - INFO - transformers.trainer -     Num examples = 71
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:52 - INFO - transformers.trainer -     Batch size = 8
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:00<00:00, 49.90it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 50.31it/s]
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:52 - INFO - transformers.trainer -   {'eval_loss': 0.6930272446738349, 'eval_acc': 0.4788732394366197, 'epoch': 6.0, 'step': 120}
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:52 - INFO - __main__ -   ***** Eval results wnli *****
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:52 - INFO - __main__ -     eval_loss = 0.6930272446738349
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:52 - INFO - __main__ -     eval_acc = 0.4788732394366197
[2m[36m(Process_task pid=561, ip=10.130.32.114)[0m 06/17/2022 07:09:52 - INFO - __main__ -     epoch = 6.0
2022-06-17 07:09:54 roberta-base lr-2e-5 WNLI seed-43 took 42.9s on mycluster-ray-worker-type-78bjh ... 4 of 4 subtasks done
