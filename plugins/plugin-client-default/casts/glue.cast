{"version": 2, "width": 94, "height": 37, "timestamp": 1659034553, "env": {"SHELL": "/bin/bash", "TERM": "xterm-256color"}, "title": "CodeFlare GLUE Demo"}
[0.020246, "o", "\u001b[?1034hbash-3.2$ "]
[1.49787, "o", "c"]
[1.611398, "o", "o"]
[1.712314, "o", "d"]
[1.888292, "o", "e"]
[2.12134, "o", "f"]
[2.240097, "o", "l"]
[2.329355, "o", "a"]
[2.397365, "o", "r"]
[2.449291, "o", "e"]
[2.512393, "o", " "]
[2.67058, "o", "-"]
[3.057613, "o", "p"]
[3.327094, "o", " "]
[3.768358, "o", "a"]
[4.066365, "o", "w"]
[4.290411, "o", "s"]
[4.443427, "o", "-"]
[4.567367, "o", "c"]
[4.716272, "o", "f"]
[4.841333, "o", "-"]
[5.068637, "o", "t"]
[5.253387, "o", "r"]
[5.325047, "o", "a"]
[5.400483, "o", "i"]
[5.470057, "o", "n"]
[6.091661, "o", "\r\n"]
[6.445247, "o", "\u001b[1;1H"]
[6.445504, "o", "\u001b[0J"]
[6.503809, "o", "\u001b[7m\u001b[1m Project Codeflare \u001b[22m\u001b[27m\r\n"]
[6.504097, "o", "  Welcome to \u001b]8;;https://research.ibm.com/blog/codeflare-ml-experiments\u0007CodeFlare\u001b]8;;\u0007, tooling to drastically reduce time to set up, run, and scale machine-learning logic.\r\n\r\n"]
[6.507216, "o", "\u001b[?25l"]
[6.510523, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 1: What do you want to do today? \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mStart a new Run\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[0m\u001b[0m\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[0m\u001b[0m  I would like to configure and fire off a run.\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[24m\u001b[39m\r\n  \u001b[1mConnect Dashboard to an existing Run\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  I would like to visualize the resource consumption, status, and logs of a run in progress.\r\n\r\n  \u001b[1mBoot up a Cloud Computer\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  I want to configure and boot up a Cloud Computer.\r\n\r\n  \u001b[1mShut down a Cloud Computer\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  I want to save money, and take one of my Cloud Computers offline.\r\n"]
[6.5108, "o", "\u001b[12A\u001b[47G"]
[8.325102, "o", "\u001b[12B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G"]
[8.32515, "o", "\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 1: What do you want to do today? \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mStart a new Run\u001b[39m"]
[8.325316, "o", "\u001b[14D"]
[8.325424, "o", "\r\n"]
[8.372556, "o", "\u001b[?25l"]
[8.373075, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 2: What kind of application do you want to run? \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mFine Tuning Demos\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[0m\u001b[0m\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[0m\u001b[0m  Fine tuning means taking weights of a trained neural network and use it as initialization for a new model being trained on data from the same domain.\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[24m\u001b[39m\r\n  \u001b[1mTraining Demos\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  The process of training an ML model involves providing an ML algorithm (that is, the learning algorithm) with training data to learn from. The term ML model refers to the model artifact that is created by the training process.\r\n\r\n  \u001b[1mBring Your Own Code\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  This path provides a way for you to run your own custom code on a remote ray cluster.\r\n"]
[8.373254, "o", "\u001b[9A\u001b[62G"]
[10.367391, "o", "\u001b[9B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 2: What kind of application do you want to run? \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n  \u001b[1mFine Tuning Demos\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[0m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  Fine tuning means taking weights of a trained neural network and use it as initialization for a new model being trained on data from the same domain.\r\n\r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mTraining Demos\u001b[22m\u001b[0m\u001b[0m\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[0m\u001b[0m  The process of training an ML model involves providing an ML algorithm (that is, the learning algorithm) with training data to learn from. The term ML model refers to the model artifact that is created by the training process.\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[24m\u001b[39m\r\n  \u001b[1mBring Your Own Code\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  This path provides a way for you to run your own custom code on a remote ray cluster.\r\n"]
[10.36761, "o", "\u001b[9A\u001b[62G"]
[10.560717, "o", "\u001b[9B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 2: What kind of application do you want to run? \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n  \u001b[1mFine Tuning Demos\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[0m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  Fine tuning means taking weights of a trained neural network and use it as initialization for a new model being trained on data from the same domain.\r\n\r\n  \u001b[1mTraining Demos\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  The process of training an ML model involves providing an ML algorithm (that is, the learning algorithm) with training data to learn from. The term ML model refers to the model artifact that is created by the training process.\r\n\r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mBring Your Own Code\u001b[22m\u001b[0m\u001b[0m\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[0m\u001b[0m  This path provides a way for you to run your own custom code on a remote ray cluster.\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[24m\u001b[39m"]
[10.560913, "o", "\u001b[9A\u001b[62G"]
[11.104796, "o", "\u001b[9B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 2: What kind of application do you want to run? \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n  \u001b[1mFine Tuning Demos\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[0m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  Fine tuning means taking weights of a trained neural network and use it as initialization for a new model being trained on data from the same domain.\r\n\r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mTraining Demos\u001b[22m\u001b[0m\u001b[0m\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[0m\u001b[0m  The process of training an ML model involves providing an ML algorithm (that is, the learning algorithm) with training data to learn from. The term ML model refers to the model artifact that is created by the training process.\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[24m\u001b[39m\r\n  \u001b[1mBring Your Own Code\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  This path provides a way for you to run your own custom code on a remote ray cluster.\r\n"]
[11.104841, "o", "\u001b[9A\u001b[62G"]
[11.290139, "o", "\u001b[9B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 2: What kind of application do you want to run? \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mFine Tuning Demos\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[0m\u001b[0m\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[0m\u001b[0m  Fine tuning means taking weights of a trained neural network and use it as initialization for a new model being trained on data from the same domain.\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[24m\u001b[39m\r\n  \u001b[1mTraining Demos\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  The process of training an ML model involves providing an ML algorithm (that is, the learning algorithm) with training data to learn from. The term ML model refers to the model artifact that is created by the training process.\r\n\r\n  \u001b[1mBring Your Own Code\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  This path provides a way for you to run your own custom code on a remote ray cluster.\r\n"]
[11.290194, "o", "\u001b[9A\u001b[62G"]
[11.643342, "o", "\u001b[9B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G"]
[11.643389, "o", "\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 2: What kind of application do you want to run? \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mFine Tuning Demos\u001b[39m"]
[11.643532, "o", "\u001b[16D"]
[11.643642, "o", "\r\n"]
[11.672376, "o", "\u001b[?25l"]
[11.672772, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 3: Which fine-tuning application do you want to run? \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mGLUE\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[0m\u001b[0m\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[0m\u001b[0m  The General Language Understanding Evaluation (GLUE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems. GLUE consists of:\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[24m\u001b[39m"]
[11.672799, "o", "\u001b[3A\u001b[67G"]
[12.39222, "o", "\u001b[3B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 3: Which fine-tuning application do you want to run? \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mGLUE\u001b[39m"]
[12.392267, "o", "\u001b[3D"]
[12.392429, "o", "\r\n"]
[12.493805, "o", "\u001b[?25l"]
[12.49414, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 4: Choose an S3 Provider \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mAWS\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[24m\u001b[39m\r\n  \u001b[1mIBM\u001b[22m"]
[12.494249, "o", "\u001b[2A\u001b[39G"]
[13.957389, "o", "\u001b[2B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 4: Choose an S3 Provider \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mAWS\u001b[39m"]
[13.957444, "o", "\u001b[2D\r\n"]
[14.649362, "o", "\u001b[?25l"]
[14.649569, "o", "\u001b[1G\u001b[1G"]
[14.64979, "o", "\u001b[36m⠋\u001b[39m \u001b[2mExpanding \u001b[34mS3 Buckets\u001b[39m\u001b[22m"]
[14.730772, "o", "\u001b[1G"]
[14.731049, "o", "\u001b[0K\u001b[36m⠙\u001b[39m \u001b[2mExpanding \u001b[34mS3 Buckets\u001b[39m\u001b[22m"]
[14.811589, "o", "\u001b[1G\u001b[0K\u001b[36m⠹\u001b[39m \u001b[2mExpanding \u001b[34mS3 Buckets\u001b[39m\u001b[22m"]
[14.890963, "o", "\u001b[1G\u001b[0K"]
[14.891117, "o", "\u001b[36m⠸\u001b[39m \u001b[2mExpanding \u001b[34mS3 Buckets\u001b[39m\u001b[22m"]
[14.971808, "o", "\u001b[1G\u001b[0K"]
[14.971862, "o", "\u001b[36m⠼\u001b[39m \u001b[2mExpanding \u001b[34mS3 Buckets\u001b[39m\u001b[22m"]
[15.053131, "o", "\u001b[1G\u001b[0K"]
[15.053215, "o", "\u001b[36m⠴\u001b[39m \u001b[2mExpanding \u001b[34mS3 Buckets\u001b[39m\u001b[22m"]
[15.134215, "o", "\u001b[1G\u001b[0K"]
[15.13437, "o", "\u001b[36m⠦\u001b[39m \u001b[2mExpanding \u001b[34mS3 Buckets\u001b[39m\u001b[22m"]
[15.214295, "o", "\u001b[1G"]
[15.214352, "o", "\u001b[0K\u001b[36m⠧\u001b[39m \u001b[2mExpanding \u001b[34mS3 Buckets\u001b[39m\u001b[22m"]
[15.295539, "o", "\u001b[1G\u001b[0K\u001b[36m⠇\u001b[39m \u001b[2mExpanding \u001b[34mS3 Buckets\u001b[39m\u001b[22m"]
[15.355483, "o", "\u001b[1G\u001b[0K\u001b[?25h"]
[15.355622, "o", "\u001b[32m✔\u001b[39m \u001b[2mExpanding \u001b[34mS3 Buckets\u001b[39m\u001b[22m\r\n"]
[15.37271, "o", "\u001b[?25l"]
[15.373697, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 5: Choose an S3 Bucket (S3 Bucket for Run Data) \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mbrowsey\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[24m\u001b[39m\r\n  \u001b[1mcommoncrawlclient\u001b[22m\r\n  \u001b[1mdata-load-test\u001b[22m\r\n  \u001b[1mkiwi-testdest\u001b[22m\r\n  \u001b[1mnorberto\u001b[22m\r\n  \u001b[1mstarpit-norcal\u001b[22m\r\n  \u001b[1mtravis-shell\u001b[22m\r\n  \u001b[90m─────\u001b[39m\r\n  \u001b[1m📁 Create a new bucket\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  You may choose to create a new S3 bucket.\r\n\u001b[11A\u001b[62G"]
[15.973256, "o", "\u001b[11B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 5: Choose an S3 Bucket (S3 Bucket for Run Data) \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mbrowsey\u001b[39m"]
[15.973392, "o", "\u001b[6D\r\n"]
[16.183122, "o", "\u001b[?25l"]
[16.183459, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 6: Pick a Ray Target \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mRun on a Kubernetes Cluster\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[0m\u001b[0m\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[0m\u001b[0m  This will install Ray on a Kubernetes context of your choosing.\u001b[24m\u001b[39m\r\n\u001b[36m\u001b[4m\u001b[24m\u001b[39m\r\n  \u001b[1mRun Locally\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  This will install Ray on your laptop.\r\n"]
[16.183553, "o", "\u001b[6A\u001b[35G"]
[17.144223, "o", "\u001b[6B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 6: Pick a Ray Target \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mRun on a Kubernetes Cluster\u001b[39m"]
[17.144268, "o", "\u001b[26D\r\n"]
[17.226092, "o", "\u001b[?25l"]
[17.226471, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 7: Choose a Kubernetes context \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mdefault/api-codeflare-train-v11-codeflare-openshift-com:6443/kube:admin\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[24m\u001b[39m\r\n  \u001b[1mdefault/c115-e-us-south-containers-cloud-ibm-com:30751/IAM#nickm@us.ibm.com\u001b[22m\r\n  \u001b[1mdocker-desktop\u001b[22m\r\n  \u001b[1mnvidia-gpu-operator/api-codeflare-train-v11-codeflare-openshift-com:6443/kube:admin\u001b[22m\r\n  \u001b[1mray/c115-e-us-south-containers-cloud-ibm-com:30751/IAM#nickm@us.ibm.com\u001b[22m\u001b[5A\u001b[45G"]
[19.587061, "o", "\u001b[5B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 7: Choose a Kubernetes context \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n  \u001b[1mdefault/api-codeflare-train-v11-codeflare-openshift-com:6443/kube:admin\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[0m\r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mdefault/c115-e-us-south-containers-cloud-ibm-com:30751/IAM#nickm@us.ibm.com\u001b[22m\u001b[24m\u001b[39m\r\n  \u001b[1mdocker-desktop\u001b[22m\r\n  \u001b[1mnvidia-gpu-operator/api-codeflare-train-v11-codeflare-openshift-com:6443/kube:admin\u001b[22m\r\n  \u001b[1mray/c115-e-us-south-containers-cloud-ibm-com:30751/IAM#nickm@us.ibm.com\u001b[22m"]
[19.587213, "o", "\u001b[5A\u001b[45G"]
[19.896655, "o", "\u001b[5B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 7: Choose a Kubernetes context \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mdefault/api-codeflare-train-v11-codeflare-openshift-com:6443/kube:admin\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[24m\u001b[39m\r\n  \u001b[1mdefault/c115-e-us-south-containers-cloud-ibm-com:30751/IAM#nickm@us.ibm.com\u001b[22m\r\n  \u001b[1mdocker-desktop\u001b[22m\r\n  \u001b[1mnvidia-gpu-operator/api-codeflare-train-v11-codeflare-openshift-com:6443/kube:admin\u001b[22m\r\n  \u001b[1mray/c115-e-us-south-containers-cloud-ibm-com:30751/IAM#nickm@us.ibm.com\u001b[22m"]
[19.896821, "o", "\u001b[5A\u001b[45G"]
[20.358769, "o", "\u001b[5B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 7: Choose a Kubernetes context \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mdefault/api-codeflare-train-v11-codeflare-openshift-com:6443/kube:admin\u001b[39m"]
[20.359036, "o", "\u001b[70D\r\n\r\n"]
[20.733877, "o", "\u001b[?25l"]
[20.734247, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 8: Target Kubernetes Namespace for Ray Cluster \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mnvidia-gpu-operator\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[24m\u001b[39m\r\n  \u001b[1masmalvan-test\u001b[22m\r\n  \u001b[1mcodeflare-train-project\u001b[22m\r\n  \u001b[1mdefault\u001b[22m\r\n  \u001b[1mmadns\u001b[22m\r\n  \u001b[1mray\u001b[22m\r\n  \u001b[1mvolcano-monitoring\u001b[22m\r\n  \u001b[1mvolcano-system\u001b[22m\r\n  \u001b[1mCreate a namespace\u001b[22m\u001b[9A\u001b[61G"]
[22.544653, "o", "\u001b[9B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 8: Target Kubernetes Namespace for Ray Cluster \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mnvidia-gpu-operator\u001b[39m"]
[22.5447, "o", "\u001b[18D\r\n"]
[22.835868, "o", "\u001b[?25l"]
[22.836804, "o", "\u001b[?25l"]
[22.836929, "o", "\u001b[?25l"]
[22.837019, "o", "\u001b[?25l\u001b[?25l"]
[22.837063, "o", "\u001b[?25l"]
[22.837178, "o", "\u001b[?25l"]
[22.837305, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 9: Configure your Ray Resource Requirements \u001b[22m\u001b[27m\u001b[39m  \r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[36m\u001b[1mNumber of CPUs\u001b[22m\u001b[39m \u001b[90m:\u001b[39m \u001b[46m\u001b[30m\u001b[30m1\u001b[39m\u001b[30m\u001b[39m\u001b[49m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of GPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMinimum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMaximum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mWorker Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mHead Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m"]
[22.837342, "o", "\u001b[6A\u001b[57G"]
[22.837667, "o", "\u001b[?25l\u001b[?25l\u001b[?25l"]
[22.837694, "o", "\u001b[?25l"]
[22.837832, "o", "\u001b[?25l\u001b[?25l"]
[22.83797, "o", "\u001b[6B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 9: Configure your Ray Resource Requirements \u001b[22m\u001b[27m\u001b[39m  \r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[36m\u001b[1mNumber of CPUs\u001b[22m\u001b[39m \u001b[90m:\u001b[39m \u001b[46m\u001b[30m\u001b[30m1\u001b[39m\u001b[30m\u001b[39m\u001b[49m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of GPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMinimum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMaximum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mWorker Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mHead Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m"]
[22.837998, "o", "\u001b[6A\u001b[57G"]
[24.297424, "o", "\u001b[?25l"]
[24.29747, "o", "\u001b[?25l"]
[24.297486, "o", "\u001b[?25l"]
[24.297679, "o", "\u001b[?25l\u001b[?25l"]
[24.297817, "o", "\u001b[?25l\u001b[6B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G"]
[24.297849, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 9: Configure your Ray Resource Requirements \u001b[22m\u001b[27m\u001b[39m  \r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of CPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[36m\u001b[1mNumber of GPUs\u001b[22m\u001b[39m \u001b[90m:\u001b[39m \u001b[46m\u001b[30m\u001b[30m1\u001b[39m\u001b[30m\u001b[39m\u001b[49m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMinimum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMaximum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mWorker Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mHead Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m"]
[24.297978, "o", "\u001b[6A\u001b[57G"]
[24.481703, "o", "\u001b[?25l\u001b[?25l"]
[24.48175, "o", "\u001b[?25l\u001b[?25l"]
[24.481765, "o", "\u001b[?25l"]
[24.481926, "o", "\u001b[?25l\u001b[6B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 9: Configure your Ray Resource Requirements \u001b[22m\u001b[27m\u001b[39m  \r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of CPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of GPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[36m\u001b[1mMinimum Workers\u001b[22m\u001b[39m \u001b[90m:\u001b[39m \u001b[46m\u001b[30m\u001b[30m1\u001b[39m\u001b[30m\u001b[39m\u001b[49m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMaximum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mWorker Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mHead Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m"]
[24.481954, "o", "\u001b[6A\u001b[57G"]
[24.661666, "o", "\u001b[?25l\u001b[?25l"]
[24.661721, "o", "\u001b[?25l\u001b[?25l\u001b[?25l"]
[24.66189, "o", "\u001b[?25l"]
[24.66205, "o", "\u001b[6B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 9: Configure your Ray Resource Requirements \u001b[22m\u001b[27m\u001b[39m  \r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of CPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of GPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMinimum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[36m\u001b[1mMaximum Workers\u001b[22m\u001b[39m \u001b[90m:\u001b[39m \u001b[46m\u001b[30m\u001b[30m1\u001b[39m\u001b[30m\u001b[39m\u001b[49m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mWorker Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mHead Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\u001b[6A\u001b[57G"]
[24.84177, "o", "\u001b[?25l"]
[24.841816, "o", "\u001b[?25l"]
[24.841831, "o", "\u001b[?25l"]
[24.842023, "o", "\u001b[?25l"]
[24.842128, "o", "\u001b[?25l\u001b[?25l\u001b[6B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 9: Configure your Ray Resource Requirements \u001b[22m\u001b[27m\u001b[39m  \r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of CPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of GPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMinimum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMaximum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[36m\u001b[1mWorker Memory\u001b[22m\u001b[39m \u001b[90m:\u001b[39m \u001b[46m\u001b[30m\u001b[30m3\u001b[39m\u001b[30m\u001b[39m\u001b[49m\u001b[2m2Gi\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mHead Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\u001b[6A\u001b[57G"]
[25.165685, "o", "\u001b[?25l"]
[25.165732, "o", "\u001b[?25l\u001b[?25l"]
[25.165771, "o", "\u001b[?25l"]
[25.16579, "o", "\u001b[?25l\u001b[?25l"]
[25.165963, "o", "\u001b[6B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 9: Configure your Ray Resource Requirements \u001b[22m\u001b[27m\u001b[39m  \r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of CPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of GPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMinimum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[36m\u001b[1mMaximum Workers\u001b[22m\u001b[39m \u001b[90m:\u001b[39m \u001b[46m\u001b[30m\u001b[30m1\u001b[39m\u001b[30m\u001b[39m\u001b[49m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mWorker Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mHead Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\u001b[6A\u001b[57G"]
[25.359498, "o", "\u001b[?25l"]
[25.359551, "o", "\u001b[?25l\u001b[?25l"]
[25.359569, "o", "\u001b[?25l"]
[25.359758, "o", "\u001b[?25l"]
[25.3598, "o", "\u001b[?25l\u001b[6B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 9: Configure your Ray Resource Requirements \u001b[22m\u001b[27m\u001b[39m  \r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of CPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of GPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[36m\u001b[1mMinimum Workers\u001b[22m\u001b[39m \u001b[90m:\u001b[39m \u001b[46m\u001b[30m\u001b[30m1\u001b[39m\u001b[30m\u001b[39m\u001b[49m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMaximum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mWorker Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mHead Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\u001b[6A\u001b[57G"]
[25.535634, "o", "\u001b[?25l"]
[25.535677, "o", "\u001b[?25l\u001b[?25l"]
[25.535693, "o", "\u001b[?25l"]
[25.535841, "o", "\u001b[?25l"]
[25.535958, "o", "\u001b[?25l\u001b[6B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 9: Configure your Ray Resource Requirements \u001b[22m\u001b[27m\u001b[39m  \r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mNumber of CPUs\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[36m\u001b[1mNumber of GPUs\u001b[22m\u001b[39m \u001b[90m:\u001b[39m \u001b[46m\u001b[30m\u001b[30m1\u001b[39m\u001b[30m\u001b[39m\u001b[49m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMinimum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mMaximum Workers\u001b[22m \u001b[90m:\u001b[39m \u001b[2m1\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mWorker Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\r\n\u001b[2m\u001b[90m⊙\u001b[39m\u001b[22m \u001b[1mHead Memory\u001b[22m \u001b[90m:\u001b[39m \u001b[2m32Gi\u001b[22m\u001b[6A\u001b[57G"]
[25.941779, "o", "\u001b[6B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 9: Configure your Ray Resource Requirements \u001b[22m\u001b[27m\u001b[39m  "]
[25.941832, "o", "\r\n"]
[26.204001, "o", "\u001b[32m▶\u001b[39m Stream out Events from the Ray Head Node\r\n"]
[26.610109, "o", "\u001b[32m▶\u001b[39m Port-forward to the Ray API\r\n"]
[27.474317, "o", "\u001b[?25l"]
[27.474776, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 10: Choose an S3 Bucket (Choose the bucket that contains your model and glue data) \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mbrowsey\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[24m\u001b[39m\r\n  \u001b[1mcommoncrawlclient\u001b[22m\r\n  \u001b[1mdata-load-test\u001b[22m\r\n  \u001b[1mkiwi-testdest\u001b[22m\r\n  \u001b[1mnorberto\u001b[22m\r\n  \u001b[1mstarpit-norcal\u001b[22m\r\n  \u001b[1mtravis-shell\u001b[22m\r\n  \u001b[90m─────\u001b[39m\r\n  \u001b[1m📁 Create a new bucket\u001b[22m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[0m  You may choose to create a new S3 bucket.\r\n"]
[27.474803, "o", "\u001b[11A\u001b[97G"]
[29.50206, "o", "\u001b[11B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 10: Choose an S3 Bucket (Choose the bucket that contains your model and glue data) \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mbrowsey\u001b[39m"]
[29.502106, "o", "\u001b[7D\r\n\r\n"]
[29.819992, "o", "\u001b[?25l"]
[29.820418, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 11:  (Choose your Model File) \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mroberta-base\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[24m\u001b[39m\r\n  \u001b[1mglue_data\u001b[22m\r\n  \u001b[1mgood\u001b[22m\r\n  \u001b[1mgood.csv\u001b[22m\r\n  \u001b[1mcodeflare/\u001b[22m\r\n  \u001b[1mcommoncrawl/\u001b[22m\r\n  \u001b[1mmlflow/\u001b[22m\r\n  \u001b[1mtensorboard/\u001b[22m\u001b[8A\u001b[44G"]
[33.511875, "o", "\u001b[8B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 11:  (Choose your Model File) \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mroberta-base\u001b[39m"]
[33.511914, "o", "\u001b[11D"]
[33.512029, "o", "\r\n"]
[33.678329, "o", "\u001b[?25l"]
[33.678822, "o", "\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 12:  (Choose your Glue Data File) \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mglue_data\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[24m\u001b[39m\r\n  \u001b[1mgood\u001b[22m\r\n  \u001b[1mgood.csv\u001b[22m\r\n  \u001b[1mroberta-base\u001b[22m\r\n  \u001b[1mcodeflare/\u001b[22m\r\n  \u001b[1mcommoncrawl/\u001b[22m\r\n  \u001b[1mmlflow/\u001b[22m\r\n  \u001b[1mtensorboard/\u001b[22m\u001b[8A\u001b[48G"]
[34.587353, "o", "\u001b[8B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 12:  (Choose your Glue Data File) \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n  \u001b[1mglue_data\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[0m\r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mgood\u001b[22m\u001b[24m\u001b[39m\r\n  \u001b[1mgood.csv\u001b[22m\r\n  \u001b[1mroberta-base\u001b[22m\r\n  \u001b[1mcodeflare/\u001b[22m\r\n  \u001b[1mcommoncrawl/\u001b[22m\r\n  \u001b[1mmlflow/\u001b[22m\r\n  \u001b[1mtensorboard/\u001b[22m"]
[34.587397, "o", "\u001b[8A\u001b[48G"]
[34.8162, "o", "\u001b[8B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[36m?\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 12:  (Choose your Glue Data File) \u001b[22m\u001b[27m\u001b[39m \u001b[2m…\u001b[22m \r\n\u001b[36m❯\u001b[39m \u001b[36m\u001b[4m\u001b[1mglue_data\u001b[22m\u001b[0m\u001b[33m\u001b[2m  ◄ you selected this last time\u001b[22m\u001b[39m\u001b[36m\u001b[0m\u001b[24m\u001b[39m\r\n  \u001b[1mgood\u001b[22m\r\n  \u001b[1mgood.csv\u001b[22m\r\n  \u001b[1mroberta-base\u001b[22m\r\n  \u001b[1mcodeflare/\u001b[22m\r\n  \u001b[1mcommoncrawl/\u001b[22m\r\n  \u001b[1mmlflow/\u001b[22m\r\n  \u001b[1mtensorboard/\u001b[22m"]
[34.816355, "o", "\u001b[8A\u001b[48G"]
[35.164644, "o", "\u001b[8B\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[F\u001b[2K\u001b[1G\u001b[32m✔\u001b[39m \u001b[33m\u001b[7m\u001b[1m Choice 12:  (Choose your Glue Data File) \u001b[22m\u001b[27m\u001b[39m \u001b[2m·\u001b[22m \u001b[36mglue_data\u001b[39m"]
[35.164694, "o", "\u001b[8D\r\n"]
[35.216173, "o", "\u001b[32m▶\u001b[39m Install Python Packages\r\n"]
[36.900391, "o", "\u001b[37mJob submission server address\u001b[39m: \u001b[1mhttp://127.0.0.1:9757\u001b[22m\r\n"]
[37.046117, "o", "2022-07-28 14:56:30,751\tINFO dashboard_sdk.py:276 -- Uploading package gcs://_ray_pkg_fc41f9c1100cbac6.zip.\r\n"]
[37.047914, "o", "2022-07-28 14:56:30,753\tINFO packaging.py:414 -- Creating a file package for local directory '/var/folders/2k/7mgd1tq55gdbghf0xkl2t_l80000gp/T/tmp-24531-NLDWUmmovlRc'.\r\n"]
[37.205744, "o", "\r\n"]
[37.205841, "o", "\u001b[32m-----------------------------------------------------------------\u001b[39m\r\n\u001b[32mJob 'eecc0ef8-8c31-4487-b7bc-70fe40d07099' submitted successfully\u001b[39m\r\n"]
[37.205881, "o", "\u001b[32m-----------------------------------------------------------------\u001b[39m\r\n\r\n"]
[37.206181, "o", "\u001b[36mNext steps\u001b[39m\r\n  Query the logs of the job:\r\n    \u001b[1mray job logs eecc0ef8-8c31-4487-b7bc-70fe40d07099\u001b[22m\r\n  Query the status of the job:\r\n    \u001b[1mray job status eecc0ef8-8c31-4487-b7bc-70fe40d07099\u001b[22m\r\n  Request the job to be stopped:\r\n    \u001b[1mray job stop eecc0ef8-8c31-4487-b7bc-70fe40d07099\u001b[22m\r\n"]
[37.206325, "o", "\r\n"]
[37.270428, "o", "\u001b[0m"]
[38.227094, "o", "error: pod, type/name or --filename must be specified\r\n"]
[38.457293, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:32.195\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:32.195\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:32.195\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:32.195\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:32.195\u001b[0m\r\n"]
[39.428113, "o", "\r\n"]
[39.445133, "o", "👉 \u001b[36mLogs will be stored in this local staging directory: \u001b[1m/Users/nickm/Library/Application Support/madwizard-nodejs/aws-cf-train/jobs/eecc0ef8-8c31-4487-b7bc-70fe40d07099\u001b(B\u001b[m\r\n"]
[39.46036, "o", "👉 \u001b[36mLogs will also be stored in s3: \u001b[1ms3://browsey/codeflare/eecc0ef8-8c31-4487-b7bc-70fe40d07099\u001b(B\u001b[m\r\n"]
[40.457782, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:34.195\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:34.195\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:34.195\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Tot"]
[40.457875, "o", "al\t\t\t\u001b"]
[40.458014, "o", "[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:34.195\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t"]
[40.468864, "o", "\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:34.195\u001b[0m\r\n"]
[40.564155, "o", "\r\n2022-07-28 11:56:34 Starting Glue benchmark ---------------\r\nmodel: roberta-base\r\ngluedata: glue_data\r\nbucket: browsey\r\ntasks: WNLI\r\nseeds: 40 41 42 43\r\nlearning_rate: 2e-05\r\nsavemodel: True\r\nray_service: glue-cluster-ray-head:10001\r\n"]
[41.561671, "o", "S3 data looks good in bucket=browsey\r\n Found actor=DataRefsActor with state {'glue_data': 'Cached', 'roberta-base': 'Cached'}\r\n2022-07-28 11:56:34 Submitted 4 subtasks\r\n"]
[42.459091, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:36.196\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:36.196\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:36.196\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:36.196\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:36.196\u001b[0m\r\n"]
[43.564474, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Node ID: NodeID(527c1193edeefb4906609f81f5feb1196cd59c34221f292157fd2aa8)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m GPU IDs: [0]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:56:36 Get glue_data data reference from data actor\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:56:36 Data: try cache get glue_data\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:56:36 Data: done cache get glue_data length=405875765 took 0.24s\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:56:36 Data: try unpack glue_data tarfile\r\n"]
[44.459068, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:38.196\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:38.196\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:38.196\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:38.196\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:38.196\u001b[0m\r\n"]
[46.45975, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:40.197\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:40.197\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:40.197\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:40.197\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:40.197\u001b[0m\r\n"]
[48.460255, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:42.197\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:42.197\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:42.197\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:42.197\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:42.197\u001b[0m\r\n"]
[50.461322, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:44.198\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:44.198\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:44.198\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:44.198\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:44.198\u001b[0m\r\n"]
[52.461433, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:46.198\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:46.198\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:46.198\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:46.198\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:46.198\u001b[0m\r\n"]
[54.461946, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:48.199\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:48.199\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:48.199\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:48.199\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:48.199\u001b[0m\r\n"]
[56.462339, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:50.199\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:50.199\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:50.199\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:50.199\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:50.199\u001b["]
[56.462486, "o", "0m\r\n"]
[57.590246, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:56:51 Data: done unpack glue_data tarfile took 14.05s\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:56:51 Get roberta-base data reference from data actor\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:56:51 Data: try cache get roberta-base\r\n"]
[58.463016, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:52.200\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:52.200\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:52.200\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:52.200\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:52.200\u001b[0m\r\n"]
[58.591452, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:56:52 Data: done cache get roberta-base length=1371970574 took 0.79s\r\n"]
[59.59297, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:56:52 Data: try unpack roberta-base tarfile\r\n"]
[60.464096, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:54.201\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:54.201\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:54.201\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:54.201\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:54.201\u001b[0m\r\n"]
[62.464291, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:56.201\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:56.201\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:56.201\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:56.201\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:56.201\u001b[0m\r\n"]
[64.464896, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:58.202\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:58.202\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:58.202\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:58.202\u001b[0m\r\n\u001b[31;1m 40 \u001b[0"]
[64.464962, "o", ";31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:56:58.202\u001b[0m\r\n"]
[66.465515, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:00.202\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:00.202\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:00.202\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:00.202\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:00.202\u001b[0m\r\n"]
[68.466424, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:02.203\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:02.203\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:02.203\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:02.203\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:02.203\u001b[0m\r\n"]
[70.466433, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:04.203\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:04.203\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:04.203\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:04.203\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:04.203\u001b[0m\r\n"]
[72.467201, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:06.204\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:06.204\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:06.204\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:06.204\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:06.204\u001b[0m\r\n"]
[74.46811, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:08.204\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:08.204\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:08.204\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:08.204\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:08.204\u001b[0m\r\n"]
[76.468571, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:10.205\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:10.205\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:10.205\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:10.205\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:10.205\u001b[0m\r\n"]
[78.469275, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:12.205\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:12.205\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:12.205\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:12.205\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:12.205\u001b[0m\r\n"]
[80.469469, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:14.206\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:14.206\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:14.206\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:14.206\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:14.206\u001b[0m\r\n"]
[82.470002, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:16.206\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:16.206\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:16.206\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:16.206\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:16.206\u001b[0m\r\n"]
[84.470582, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:18.207\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:18.207\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:18.207\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:18.207\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:18.207\u001b[0m\r\n"]
[86.47086, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:20.207\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:20.207\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:20.207\u001b[0m\r\n\u001b["]
[86.470918, "o", "31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:20.207\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:20.207\u001b[0m\r\n"]
[88.471777, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:22.208\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:22.208\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:22.208\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:22.208\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:22.208\u001b[0m\r\n"]
[90.472577, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:24.208\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:24.208\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:24.208\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:24.208\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:24.208\u001b[0m\r\n"]
[92.47259, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:26.209\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:26.209\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:26.209\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:26.209\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:26.209\u001b[0m\r\n"]
[94.473351, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:28.209\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:28.209\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:28.209\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:28.209\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:28.209\u001b[0m\r\n"]
[96.47415, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:30.210\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:30.210\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:30.210\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:30.210\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:30.210\u001b[0m\r\n"]
[96.654181, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:57:29 Data: done unpack roberta-base tarfile took 36.70s\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Processing task WNLI seed 40 with model roberta-base\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Will not apply HSTS. The HSTS database must be a regular and non-world-writable file.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m ERROR: could not open HSTS store at '/home/ray/.wget-hsts'. HSTS will be disabled.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m --2022-07-28 11:57:29--  https://raw.githubusercontent.com/huggingface/transformers/b0892fa0e8df02d683e05e625b3903209bff362d/examples/text-classification/run_glue.py\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Resolving raw.githubusercontent.com (raw.githubusercontent.com)... \r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Connecting "]
[96.654369, "o", "to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m HTTP request sent, awaiting response... \r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 200 OK\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Length: 9504 (9.3K) [text/plain]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Saving to: ‘run_glue.py’\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m \r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m      0K .........                                             100% 66.6M=0s\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m \r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 2022-07-28 11:57:29 (66.6 MB/s) - ‘run_glue.py’ saved [9504/9504]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m \r\n"]
[98.474324, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:32.210\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;"]
[98.474506, "o", "31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:32.210\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:32.210\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:32.210\u001b[0m\r\n\u001b[31;"]
[98.474536, "o", "1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:32.210\u001b[0m\r\n"]
[100.475261, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:34.211\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:34.211\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:34.211\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:34.211\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:34.211\u001b[0m\r\n"]
[100.664796, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:33 - INFO - transformers.training_args -   PyTorch: setting up devices\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:33 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:33 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_"]
[100.665055, "o", "epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul28_11-57-33_mycluster-ray-worker-type-82vph', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=40, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:33 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:33 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"architectures\": [\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m     \"RobertaForMaskedLM\"\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   ],\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"attenti"]
[100.665283, "o", "on_probs_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"bos_token_id\": 0,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"eos_token_id\": 2,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"finetuning_task\": \"wnli\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"gradient_checkpointing\": false,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_act\": \"gelu\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_size\": 768,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"initializer_range\": 0.02,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"intermediate_size\": 3072,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"layer_norm_eps\": 1e-05,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"max_position_embeddings\": 514,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"model_type\": \"roberta\",\r\n\u001b[2m\u001b[36m(Process_"]
[100.665518, "o", "task pid=591, ip=10.130.96.40)\u001b[0m   \"num_attention_heads\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_hidden_layers\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"pad_token_id\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"type_vocab_size\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"vocab_size\": 50265\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m }\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:33 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:33 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"architectures\": [\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m     \"RobertaForMaskedLM\"\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   ],\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"att"]
[100.665753, "o", "ention_probs_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"bos_token_id\": 0,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"eos_token_id\": 2,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"gradient_checkpointing\": false,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_act\": \"gelu\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_size\": 768,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"initializer_range\": 0.02,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"intermediate_size\": 3072,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"layer_norm_eps\": 1e-05,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"max_position_embeddings\": 514,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"model_type\": \"roberta\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_attention_heads\": 12,\r\n\u001b[2m\u001b[36m(Proc"]
[100.666042, "o", "ess_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_hidden_layers\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"pad_token_id\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"type_vocab_size\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"vocab_size\": 50265\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m }\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:34 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:34 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70"]
[100.666164, "o", "bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:34 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin\r\n"]
[102.475861, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:36.212\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:36.212\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:36.212\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:36.212\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:36.212\u001b[0m\r\n"]
[104.47679, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:38.212\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:38.212\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:38.212\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:38.212\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:38.212\u001b[0m\r\n"]
[106.477207, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:40.213\u001b[0m\r\n\u001b[31;1m 9 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:40.213\u001b[0m\r\n\u001b[31;1m 1 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:40.213\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:40.213\u001b[0m\r\n\u001b[31;1m 39 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:40.213\u001b[0m\r\n"]
[106.686576, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip="]
[106.686726, "o", "10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   *** Example ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   guid: train-0\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO -"]
[106.686765, "o", " transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 100, 4889, 10, 7756, 149, 10, 33129, 4, 520, 38, 2468, 5, 7756, 66, 6, 24, 56, 10, 4683, 4, 2, 2, 133, 33129, 56, 10, 4683, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transfor"]
[106.686888, "o", "mers.data.processors.glue -   *** Example ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   guid: train-1\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 10567, 1705, 75, 192, 5, 1289, 19, 7835, 11, 760, 9, 123, 142, 37, 16, 98, 765, 4, 2, 2, 10567, 16, 98, 765, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, "]
[106.686921, "o", "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   *** Example ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   guid: train-2\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 249, 1128, 70, 9, 5, 5188, 453, 4, 252, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 2, 133, 249, 58, 667, 7, 912, 5, 1262, 721, 11, 5, 3757, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"]
[106.687048, "o", ", attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   *** Example ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   guid: train-3\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 21976, 3905, 7734, 18, 1246, 11, 960, 4, 91, 16882, 123, 13481, 4, 2, 2, 21976, 16882, 123, 13481, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1"]
[106.688175, "o", ", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   *** Example ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   guid: train-4\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/"]
[106.688274, "o", "28/2022 11:57:39 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 1779, 17734, 219, 1113, 1348, 5, 11657, 6, 69, 985, 21, 8416, 4, 264, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 2, 19456, 21, 7316, 45, 7, 32366, 69, 6, 2432, 9828, 8, 10907, 124, 88, 69, 16471, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)\r\n\u001b[2m\u001b[36m(Process_ta"]
[106.689031, "o", "sk pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.064 s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/WNLI\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   *** Example ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   guid: dev-0\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 15160, 16, 3741, 29519, 19, 2549, 4, 85, 34, 7, 28, 17317, 4, 2, 2, 133, 2549, 34, 7, 28, 17317, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, "]
[106.689174, "o", "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   *** Example ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   guid: dev-1\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   featur"]
[106.689282, "o", "es: InputFeatures(input_ids=[0, 35903, 6536, 15, 6470, 18, 1883, 53, 79, 222, 45, 1948, 4, 2, 2, 38621, 222, 45, 1948, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   *** Example ***\r\n\u001b[2m\u001b[36"]
[106.689375, "o", "m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   guid: dev-2\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 387, 4774, 399, 75, 120, 5800, 19, 15282, 6, 54, 56, 847, 69, 160, 6, 142, 79, 2294, 8, 11590, 7, 2724, 4, 2, 2, 104, 2368, 2294, 8, 11590, 7, 2724, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,"]
[106.689469, "o", " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   *** Example ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   guid: dev-3\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 3084, 65, 9447, 622, 7, 28, 5074, 8, 20100, 4, 125, 10, 92, 892, 31, 5, 589, 9, 4222, 19902, 1655, 5839, 10648, 14, 14, 18, 2230, 141, 24, 817, 201, 619, 4, 2, 2, 1711, 18, 2230, 141, 622, 817, 201, 619, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mas"]
[106.689569, "o", "k=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   *** Example ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   guid: dev-4\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[0, 133, 313, 1705, 75, 5258, 39, 979, 142, 37, 21, 98, 2016, 4, 2, 2, 133, 979, 21, 98, 2016, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,"]
[106.690211, "o", " 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:39 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.007 s]\r\n"]
[108.477601, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:42.213\u001b[0m\r\n\u001b[31;1m 4 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:42.213\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:42.213\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:42.213\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:42.213\u001b[0m\r\n"]
[110.478546, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:44.214\u001b[0m\r\n\u001b[31;1m 8 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:44.214\u001b[0m\r\n\u001b[31;1m 1 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:44.214\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:44.214\u001b[0m\r\n\u001b[31;1m 40 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:44.214\u001b[0m\r\n"]
[111.682953, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:44 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:44 - INFO - transformers.trainer -   ***** Running training *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:44 - INFO - transformers.trainer -     Num examples = 635\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:44 - INFO - transformers.trainer -     Num Epochs = 6\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:44 - INFO - transformers.trainer -     Instantaneous batch size per device = 32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:44 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10"]
[111.683238, "o", ".130.96.40)\u001b[0m 07/28/2022 11:57:44 - INFO - transformers.trainer -     Gradient Accumulation steps = 1\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:44 - INFO - transformers.trainer -     Total optimization steps = 120\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:57:44 - INFO - transformers.trainer -     Starting fine-tuning.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  3.96it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.20it/s]\u001b[A\r\n"]
[112.479257, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:46.215\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:46.215\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:46.215\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:46.215\u001b[0m\r\n\u001b[31;1m 49 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:46.215\u001b[0m\r\n"]
[112.684445, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:04,  4.24it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.28it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.25it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.30it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.34it/s]\u001b[A\r\n"]
[113.686246, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.26it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.36it/s]\u001b[A\r\n"]
[114.479653, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:48.215\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:48.215\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:48.215\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:48.215\u001b[0m\r\n\u001b[31;1m 50 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:48.215\u001b[0m\r\n"]
[114.688064, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:03<00:01,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.39it/s]\u001b[A\r\n"]
[115.689565, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.56it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.37it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  17%|█▋        | 1/6 [00:04<00:22,  4.57s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n"]
[116.480658, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:50.216\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:50.216\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:50.216\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:50.216\u001b[0m\r\n\u001b[31;1m 50 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:50.216\u001b[0m\r\n"]
[116.69099, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.23it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.40it/s]\u001b[A\r\n"]
[117.692631, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.41it/s]\u001b[A\r\n"]
[118.480868, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:52.216\u001b[0m\r\n\u001b[31;1m 87 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:52.216\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:52.216\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:52.216\u001b[0m\r\n\u001b[31;1m 52 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:52.216\u001b[0m\r\n"]
[118.693973, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.38it/s]\u001b[A\r\n"]
[119.6957, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.39it/s]\u001b[A\r\n"]
[120.48165, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:54.217\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:54.217\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:54.217\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31"]
[120.481732, "o", "mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:54.217\u001b[0m\r\n\u001b[31;1m 53 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:54.217\u001b[0m\r\n"]
[120.697402, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.41it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  33%|███▎      | 2/6 [00:09<00:18,  4.55s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.42it/s]\u001b[A\r\n"]
[121.698821, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.41it/s]\u001b[A\r\n"]
[122.482037, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:56.217\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:56.217\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:56.217\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:56.217\u001b[0m\r\n\u001b[31;1m 53 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:56.217\u001b[0m\r\n"]
[122.699648, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.41it/s]\u001b[A\r\n"]
[123.701343, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.29it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.29it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.34it/s]\u001b[A\r\n"]
[124.490236, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:58.218\u001b[0m\r\n\u001b[31;1m 93 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:58.218\u001b[0m\r\n\u001b[31;1m 43 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:58.218\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:58.218\u001b[0m\r\n\u001b[31;1m 54 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:57:58.218\u001b[0m\r\n"]
[124.703806, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.54it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.41it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  50%|█████     | 3/6 [00:13<00:13,  4.55s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]"]
[124.704016, "o", "\u001b[A\r\n"]
[125.705491, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.39it/s]\u001b[A\r\n"]
[126.483147, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:00.219\u001b[0m\r\n\u001b[31;1m 95 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:00.219\u001b[0m\r\n\u001b[31;1m 37 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:00.219\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:00.219\u001b[0m\r\n\u001b[31;1m 53 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:00.219\u001b[0m\r\n"]
[126.707328, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.26it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.31it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.36it/s]\u001b[A\r\n"]
[127.70903, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.35it/s]\u001b[A\r\n"]
[128.4841, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:02.219\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:02.219\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:02.219\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:02.219\u001b[0m\r\n\u001b[31;1m 55 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:02.219\u001b[0m\r\n"]
[128.710831, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.31it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.34it/s]\u001b[A\r\n"]
[129.712932, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.52it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.37it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  67%|██████▋   | 4/6 [00:18<00:09,  4.56s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.43it/s]\u001b[A\r\n"]
[130.484495, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:04.220\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:04.220\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:04.220\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:04.220\u001b[0m\r\n\u001b[31;1m 55 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:04.220\u001b[0m\r\n"]
[130.713619, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.30it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.34it/s]\u001b[A\r\n"]
[131.714953, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.38it/s]\u001b[A\r\n"]
[132.484953, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:06.220\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:06.220\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:06.220\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:06.220\u001b[0"]
[132.485093, "o", "m\r\n\u001b[31;1m 55 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2"]
[132.495835, "o", "mmycluster-ray-worker-type-82vph 2022/07/28 11:58:06.220\u001b[0m\r\n"]
[132.716418, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.38it/s]\u001b[A\r\n"]
[133.718228, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.51it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.39it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  83%|████████▎ | 5/6 [00:22<00:04,  4.56s/it]\r\n"]
[134.485866, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:08.221\u001b[0m\r\n\u001b[31;1m 93 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:08.221\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:08.221\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:08.221\u001b[0m\r\n\u001b[31;1m 55 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:08.221\u001b[0m\r\n"]
[134.719474, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.37it/s]\u001b[A\r\n"]
[135.720578, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.40it/s]\u001b[A\r\n"]
[136.486135, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:10.221\u001b[0m\r\n\u001b[31;1m 100 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:10.221\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:10.221\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:10.221\u001b[0m\r\n\u001b[31;1m 56 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:10.221\u001b[0m\r\n"]
[136.722028, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.38it/s]\u001b[A\r\n"]
[137.724032, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.37it/s]\u001b[A\r\n"]
[138.487051, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:12.222\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:12.222\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:12.222\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:12.222\u001b[0m\r\n\u001b[31;1m 51 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:12.222\u001b[0m\r\n"]
[138.725741, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.39it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch: 100%|██████████| 6/6 [00:27<00:00,  4.56s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch: 100%|██████████| 6/6 [00:27<00:00,  4.56s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:11 - INFO - transformers.tr"]
[138.726064, "o", "ainer -\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Training completed. Do not forget to share your model on huggingface.co/models =)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:11 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:11 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32/config.json\r\n"]
[139.7277, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:12 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-40_lr-2e-5_TBATCH-32/pytorch_model.bin\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:12 - INFO - __main__ -   *** Evaluate ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:12 - INFO - transformers.trainer -   ***** Running Evaluation *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:12 - INFO - transformers.trainer -     Num examples = 71\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:12 - INFO - transformers.trainer -     Batch size = 8\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation:  56%|█████▌    | 5/9 [00:00<00:00, 49.23it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation: 100%|"]
[139.727861, "o", "██████████| 9/9 [00:00<00:00, 50.14it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:13 - INFO - transformers.trainer -   {'eval_loss': 0.6928180588616265, 'eval_acc': 0.5633802816901409, 'epoch': 6.0, 'step': 120}\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:13 - INFO - __main__ -   ***** Eval results wnli *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:13 - INFO - __main__ -     eval_loss = 0.6928180588616265\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:13 - INFO - __main__ -     eval_acc = 0.5633802816901409\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:13 - INFO - __main__ -     epoch = 6.0\r\n"]
[140.487399, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:14.222\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:14.222\u001b[0m\r\n\u001b[31;1m 12 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:14.222\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:14.222\u001b[0m\r\n\u001b[31;1m 48 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:14.222\u001b[0m\r\n"]
[141.731714, "o", "2022-07-28 11:58:14 roberta-base lr-2e-5 WNLI seed-40 took 44.3s on mycluster-ray-worker-type-82vph ... 1 of 4 subtasks done\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Node ID: NodeID(527c1193edeefb4906609f81f5feb1196cd59c34221f292157fd2aa8)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m GPU IDs: [0]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Reusing previous existing glue-dataset\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Reusing roberta-base directory\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Processing task WNLI seed 41 with model roberta-base\r\n"]
[142.488307, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:16.223\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:16.223\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:16.223\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:16.223\u001b[0m\r\n\u001b[31;1m 47 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:16.223\u001b[0m\r\n"]
[144.488538, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:18.223\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:18.223\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:18.223\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:18.223\u001b[0m\r\n\u001b[31;1m 46 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:18.223\u001b[0m\r\n"]
[145.736584, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:19 - INFO - transformers.training_args -   PyTorch: setting up devices\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:19 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:19 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_"]
[145.736785, "o", "epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul28_11-58-19_mycluster-ray-worker-type-82vph', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=41, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:19 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:19 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"architectures\": [\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m     \"RobertaForMaskedLM\"\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   ],\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"attenti"]
[145.736834, "o", "on_probs_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"bos_token_id\": 0,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"eos_token_id\": 2,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"finetuning_task\": \"wnli\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"gradient_checkpointing\": false,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_act\": \"gelu\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_size\": 768,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"initializer_range\": 0.02,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"intermediate_size\": 3072,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"layer_norm_eps\": 1e-05,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"max_position_embeddings\": 514,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"model_type\": \"roberta\",\r\n\u001b[2m\u001b[36m(Process_"]
[145.737007, "o", "task pid=591, ip=10.130.96.40)\u001b[0m   \"num_attention_heads\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_hidden_layers\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"pad_token_id\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"type_vocab_size\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"vocab_size\": 50265\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m }\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:19 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:19 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"architectures\": [\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m     \"RobertaForMaskedLM\"\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   ],\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"att"]
[145.737166, "o", "ention_probs_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"bos_token_id\": 0,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"eos_token_id\": 2,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"gradient_checkpointing\": false,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_act\": \"gelu\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_size\": 768,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"initializer_range\": 0.02,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"intermediate_size\": 3072,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"layer_norm_eps\": 1e-05,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"max_position_embeddings\": 514,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"model_type\": \"roberta\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_attention_heads\": 12,\r\n\u001b[2m\u001b[36m(Proc"]
[145.737232, "o", "ess_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_hidden_layers\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"pad_token_id\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"type_vocab_size\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"vocab_size\": 50265\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m }\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:19 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:19 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70"]
[145.737394, "o", "bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:19 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin\r\n"]
[146.489398, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:20.224\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:20.224\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:20.224\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:20.224\u001b[0m\r\n\u001b[31;1m 45 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:20.224\u001b[0m\r\n"]
[148.489923, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:22.224\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:22.224\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:22.224\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:22.224\u001b[0m\r\n\u001b[31;1m 45 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:22.224\u001b[0m\r\n"]
[150.490437, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:24.225\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:24.225\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:24.225\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:24.225\u001b[0m\r\n\u001b[31;1m 45 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:24.225\u001b[0m\r\n"]
[151.751681, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:24 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip="]
[151.751958, "o", "10.130.96.40)\u001b[0m 07/28/2022 11:58:24 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:24 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.036 s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:24 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.004 s]\r\n"]
[152.491463, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:26.226\u001b[0m\r\n\u001b[31;1m 4 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:26.226\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:26.226\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:26.226\u001b[0m\r\n\u001b[31;1m 45 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:26.226\u001b[0m\r\n"]
[154.491892, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:28.226\u001b[0m\r\n\u001b[31;1m 4 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:28.226\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:28.226\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:28.226\u001b[0m\r\n\u001b[31;1m 45 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:28.226\u001b[0m\r\n"]
[155.75845, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:29 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:29 - INFO - transformers.trainer -   ***** Running training *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:29 - INFO - transformers.trainer -     Num examples = 635\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:29 - INFO - transformers.trainer -     Num Epochs = 6\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:29 - INFO - transformers.trainer -     Instantaneous batch size per device = 32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:29 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10"]
[155.758633, "o", ".130.96.40)\u001b[0m 07/28/2022 11:58:29 - INFO - transformers.trainer -     Gradient Accumulation steps = 1\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:29 - INFO - transformers.trainer -     Total optimization steps = 120\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:29 - INFO - transformers.trainer -     Starting fine-tuning.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]\r\n"]
[156.492312, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:30.227\u001b[0m\r\n\u001b[31;1m 95 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:30.227\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:30.227\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:30.227\u001b[0m\r\n\u001b[31;1m 53 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:30.227\u001b[0m\r\n"]
[156.75945, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:05,  3.75it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.07it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:04,  4.22it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.29it/s]\u001b[A\r\n"]
[157.760804, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.31it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:03,  4.24it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.29it/s]\u001b[A\r\n"]
[158.493251, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:32.228\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:32.228\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:32.228\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:32.228\u001b[0m\r\n\u001b[31;1m 56 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:32.228\u001b[0m"]
[158.50389, "o", "\r\n"]
[158.762234, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.31it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.35it/s]\u001b[A\r\n"]
[159.764891, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:03<00:01,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.32it/s]\u001b[A\r\n"]
[160.493647, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:34.228\u001b[0m\r\n\u001b[31;1m 86 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:34.228\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:34.228\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:34.228\u001b[0m\r\n\u001b[31;1m 57 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:34.228\u001b[0m\r\n"]
[160.766088, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.52it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.34it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  17%|█▋        | 1/6 [00:04<00:23,  4.61s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.31it/s]\u001b[A\r\n"]
[161.767332, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.41it/s]\u001b[A\r\n"]
[162.49437, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:36.229\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:36.229\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:36.229\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:36.229\u001b[0m\r\n\u001b[31;1m 57 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:36.229\u001b[0m\r\n"]
[162.768243, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.36it/s]\u001b[A\r\n"]
[163.770045, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.37it/s]\u001b[A\r\n"]
[164.494863, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:38.229\u001b[0m\r\n\u001b[31;1m 95 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:38.229\u001b[0m\r\n\u001b[31;1m 37 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:38.229\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:38.229\u001b[0m\r\n\u001b[31;1m 58 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:38.229\u001b[0m\r\n"]
[164.771, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.56it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.41it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  33%|███▎      | 2/"]
[164.771176, "o", "6 [00:09<00:18,  4.56s/it]\r\n"]
[165.77264, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.39it/s]\u001b[A\r\n"]
[166.495369, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:40.230\u001b[0m\r\n\u001b[31;1m 99 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:40.230\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:40.230\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:40.230\u001b[0m\r\n\u001b[31;1m 58 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:40.230\u001b[0m\r\n"]
[166.774171, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.40it/s]\u001b[A\r\n"]
[167.776102, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.38it/s]\u001b[A\r\n"]
[168.495541, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:42.230\u001b[0m\r\n\u001b[31;1m 94 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2m"]
[168.495697, "o", "mycluster-ray-worker-type-82vph 2022/07/28 11:58:42.230\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:42.230\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:42.230\u001b[0m\r\n\u001b[31;1m 58 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:42.230\u001b[0m\r\n"]
[168.778135, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.39it/s]\u001b[A\r\n"]
[169.778707, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.57it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.42it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  50%|█████     | 3/6 [00:13<00:13,  4.55s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.41it/s]\u001b[A\r\n"]
[170.496365, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:44.231\u001b[0m\r\n\u001b[31;1m 91 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:44.231\u001b[0m\r\n\u001b[31;1m 40 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:44.231\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:44.231\u001b[0m\r\n\u001b[31;1m 59 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:44.231\u001b[0m\r\n"]
[170.780498, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.40it/s]\u001b[A\r\n"]
[171.782142, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n"]
[172.497299, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:46.231\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:46.231\u001b[0m\r\n\u001b[31;1m 40 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:46.231\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:46.231\u001b[0m\r\n\u001b[31;1m 60 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:46.231\u001b[0m\r\n"]
[172.783599, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.41it/s]\u001b[A\r\n"]
[173.784695, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.56it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.42it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  67%|██████▋ "]
[173.784832, "o", "  | 4/6 [00:18<00:09,  4.54s/it]\r\n"]
[174.497645, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:48.232\u001b[0m\r\n\u001b[31;1m 90 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:48.232\u001b[0m\r\n\u001b[31;1m 40 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:48.232\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:48.232\u001b[0m\r\n\u001b[31;1m 60 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:48.232\u001b[0m\r\n"]
[174.787087, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.39it/s]\u001b[A\r\n"]
[175.787763, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.39it/s]\u001b[A\r\n"]
[176.498394, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:50.232\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:50.232\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:50.232\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:50.232\u001b[0m\r\n\u001b[31;1m 61 \u001b[0;31mTemperature.GPU\t\t\t\u001b["]
[176.509068, "o", "0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:50.232\u001b[0m\r\n"]
[176.790295, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.40it/s]\u001b[A\r\n"]
[177.791706, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.37it/s]\u001b[A\r\n"]
[178.498773, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:52.233\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:52.233\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:52.233\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:52.233\u001b[0m\r\n\u001b[31;1m 59 \u001b[0;31"]
[178.509397, "o", "mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:52.233\u001b[0m\r\n"]
[178.793166, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.40it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  83%|████████▎ | 5/6 [00:22<00:04,  4.54s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.35it/s]\u001b[A\r\n"]
[179.795824, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.43it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.39it/s]\u001b[A\r\n"]
[180.499168, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:54.233\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:54.233\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:54.233\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:54.233\u001b[0m\r\n\u001b[31;1m 61 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:54.233\u001b[0m\r\n"]
[180.797873, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.30it/s]\u001b[A\r\n"]
[181.799703, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.36it/s]\u001b[A\r\n"]
[182.500435, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:56.234\u001b[0m\r\n\u001b[31;1m 92 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:56.234\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:56.234\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:56.234\u001b[0m\r\n\u001b[31;1m 62 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:56.234\u001b[0m\r\n"]
[182.800453, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.35it/s]\u001b[A\r\n"]
[183.805274, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.50it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.38it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch: 100%|██████████| 6/6 [00:27<00:00,  4.55s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch: 100%|██████████| 6/6 [00:27<00:00,  4.55s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:56 - INFO - transformers.trainer -\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Training completed. Do not forget to share your model on huggingface.co/models =)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:56 - INFO - transformers.trainer -   Saving model che"]
[183.805325, "o", "ckpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:56 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32/config.json\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:57 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-41_lr-2e-5_TBATCH-32/pytorch_model.bin\r\n"]
[184.49998, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:58.234\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:58.234\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:58.234\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:58.234\u001b[0m\r\n\u001b[31;1m 54 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:58:58.234\u001b[0m\r\n"]
[184.803375, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:57 - INFO - __main__ -   *** Evaluate ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:57 - INFO - transformers.trainer -   ***** Running Evaluation *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:57 - INFO - transformers.trainer -     Num examples = 71\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:57 - INFO - transformers.trainer -     Batch size = 8\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 50.55it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation: 100%|██████████| 9/9 [00:00<00:00, 51.13it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:57 - INFO - transformers.trainer -   {'eval_loss': 0.6902288595835367, 'eval_acc': 0.56"]
[184.80357, "o", "33802816901409, 'epoch': 6.0, 'step': 120}\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:57 - INFO - __main__ -   ***** Eval results wnli *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:57 - INFO - __main__ -     eval_loss = 0.6902288595835367\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:57 - INFO - __main__ -     eval_acc = 0.5633802816901409\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:58:57 - INFO - __main__ -     epoch = 6.0\r\n"]
[186.500988, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:00.235\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:00.235\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:00.235\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:00.235\u001b[0m\r\n\u001b[31;1m 53 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:00.235\u001b[0m\r\n"]
[186.807471, "o", "2022-07-28 11:58:59 roberta-base lr-2e-5 WNLI seed-41 took 44.0s on mycluster-ray-worker-type-82vph ... 2 of 4 subtasks done\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Node ID: NodeID(527c1193edeefb4906609f81f5feb1196cd59c34221f292157fd2aa8)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m GPU IDs: [0]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Reusing previous existing glue-dataset\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Reusing roberta-base directory\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Processing task WNLI seed 42 with model roberta-base\r\n"]
[188.501628, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:02.235\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:02.235\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:02.235\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:02.235\u001b[0m\r\n\u001b[31;1m 52 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:02.235\u001b[0m\r\n"]
[190.501946, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:04.236\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:04.236\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:04.236\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:04.236\u001b[0m\r\n\u001b[31;1m 52 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:04.236\u001b[0m\r\n"]
[190.814542, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:03 - INFO - transformers.training_args -   PyTorch: setting up devices\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:03 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:03 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_"]
[190.814775, "o", "epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul28_11-59-03_mycluster-ray-worker-type-82vph', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:03 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:03 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"architectures\": [\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m     \"RobertaForMaskedLM\"\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   ],\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"attenti"]
[190.8151, "o", "on_probs_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"bos_token_id\": 0,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"eos_token_id\": 2,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"finetuning_task\": \"wnli\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"gradient_checkpointing\": false,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_act\": \"gelu\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_size\": 768,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"initializer_range\": 0.02,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"intermediate_size\": 3072,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"layer_norm_eps\": 1e-05,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"max_position_embeddings\": 514,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"model_type\": \"roberta\",\r\n\u001b[2m\u001b[36m(Process_"]
[190.815295, "o", "task pid=591, ip=10.130.96.40)\u001b[0m   \"num_attention_heads\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_hidden_layers\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"pad_token_id\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"type_vocab_size\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"vocab_size\": 50265\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m }\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:03 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:03 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"architectures\": [\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m     \"RobertaForMaskedLM\"\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   ],\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"att"]
[190.815437, "o", "ention_probs_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"bos_token_id\": 0,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"eos_token_id\": 2,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"gradient_checkpointing\": false,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_act\": \"gelu\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_size\": 768,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"initializer_range\": 0.02,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"intermediate_size\": 3072,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"layer_norm_eps\": 1e-05,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"max_position_embeddings\": 514,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"model_type\": \"roberta\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_attention_heads\": 12,\r\n\u001b[2m\u001b[36m(Proc"]
[190.815593, "o", "ess_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_hidden_layers\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"pad_token_id\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"type_vocab_size\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"vocab_size\": 50265\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m }\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:03 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:03 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70"]
[190.815654, "o", "bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:04 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin\r\n"]
[192.50266, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:06.236\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:06.236\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:06.236\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:06.236\u001b[0m\r\n\u001b[31;1m 52 \u001b"]
[192.513397, "o", "[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:06.236\u001b[0m\r\n"]
[194.502637, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:08.237\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:08.237\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:08.237\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:08.237\u001b[0m\r\n\u001b[31;1m 50 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:08.237\u001b[0m\r\n"]
[195.821365, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:09 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip="]
[195.82155, "o", "10.130.96.40)\u001b[0m 07/28/2022 11:59:09 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:09 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.038 s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:09 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.004 s]\r\n"]
[196.503526, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:10.237\u001b[0m\r\n\u001b[31;1m 4 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:10.237\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:10.237\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:10.237\u001b[0m\r\n\u001b[31;1m 50 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:10.237\u001b[0m\r\n"]
[198.504396, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:12.238\u001b[0m\r\n\u001b[31;1m 3 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:12.238\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:12.238\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:12.238\u001b[0m\r\n\u001b[31;1m 50 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:12.238\u001b[0m\r\n"]
[200.504523, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:14.238\u001b[0m\r\n\u001b[31;1m 99 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:14.238\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:14.238\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:14.238\u001b[0m\r\n\u001b[31;1m 53 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:14.238\u001b[0m\r\n"]
[200.866704, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:13 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:13 - INFO - transformers.trainer -   ***** Running training *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:13 - INFO - transformers.trainer -     Num examples = 635\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:13 - INFO - transformers.trainer -     Num Epochs = 6\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:13 - INFO - transformers.trainer -     Instantaneous batch size per device = 32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:13 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10"]
[200.867032, "o", ".130.96.40)\u001b[0m 07/28/2022 11:59:13 - INFO - transformers.trainer -     Gradient Accumulation steps = 1\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:13 - INFO - transformers.trainer -     Total optimization steps = 120\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:13 - INFO - transformers.trainer -     Starting fine-tuning.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:05,  3.73it/s]\u001b[A\r\n"]
[201.829644, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.07it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:04,  4.21it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.28it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.31it/s]\u001b[A\r\n"]
[202.505562, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:16.239\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:16.239\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:16.239\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:16.239\u001b[0m\r\n\u001b[31;1m 60 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:16.239\u001b[0m\r\n"]
[202.83139, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.37it/s]\u001b[A\r\n"]
[203.833234, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.23it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:03<00:01,  4.26it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.30it/s]\u001b[A\r\n"]
[204.505979, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:18.239\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:18.239\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:18.239\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:18.239\u001b[0m\r\n\u001b[31;1m 61 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:18.239\u001b[0m\r\n"]
[204.835052, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.36it/s]\u001b[A\r\n"]
[205.836138, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.54it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.34it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  17%|█▋        | 1/6 [00:04<00:23,  4.61s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.39it/s]\u001b[A\r\n"]
[206.510356, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:20.240\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:20.240\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:20.240\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:20.240\u001b[0m\r\n\u001b[31;1m 62 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:20.240\u001b[0m\r\n"]
[206.837474, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.39it/s]\u001b[A\r\n"]
[207.83923, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n"]
[208.51427, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:22.245\u001b[0m\r\n\u001b[31;1m 94 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:22.245\u001b[0m\r\n\u001b[31;1m 40 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:22.245\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:22.245\u001b[0m\r\n\u001b[31;1m 62 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:22.245\u001b[0m\r\n"]
[208.841376, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.31it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.33it/s]\u001b[A\r\n"]
[209.842489, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.31it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.52it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.39it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  33%|███▎      | 2/6 [00:09<00:18,  4.58s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n"]
[210.511781, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:24.245\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:24.245\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:24.245\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:24.245\u001b[0m\r\n\u001b[31;1m 63 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:24.245\u001b[0m\r\n"]
[210.844254, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.10it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.28it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.35it/s]\u001b[A\r\n"]
[211.845733, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.35it/s]\u001b[A\r\n"]
[212.512528, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:26.246\u001b[0m\r\n\u001b[31;1m 99 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:26.246\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:26.246\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:26.246\u001b[0m\r\n\u001b[31;1m 63 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:26.246\u001b[0m\r\n"]
[212.847347, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.27it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.28it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:03<00:01,  4.32it/s]\u001b[A\r\n"]
[213.848228, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.37it/s]\u001b[A\r\n"]
[214.513148, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:28.246\u001b[0m\r\n\u001b[31;1m 94 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:28.246\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:28.246\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:28.246\u001b[0m\r\n\u001b[31;1m 63 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:28.246\u001b[0m\r\n"]
[214.849916, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.55it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.37it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  50%|█████     | 3/6 [00:13<00:13,  4.58s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.38it/s]\u001b[A\r\n"]
[215.851259, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.37it/s]\u001b[A\r\n"]
[216.513183, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:30.247\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:30.247\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:30.247\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Tota"]
[216.513287, "o", "l\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:30.247\u001b[0m\r\n\u001b[31;1m 62 \u001b[0;31mTemperature.GPU"]
[216.524121, "o", "\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:30.247\u001b[0m\r\n"]
[216.852971, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.35it/s]\u001b[A\r\n"]
[217.854238, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.30it/s]\u001b[A\r\n"]
[218.514059, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:32.247\u001b[0m\r\n\u001b[31;1m 86 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:32.247\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:32.247\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:32.247\u001b[0m\r\n\u001b[31;1m 64 \u001b[0;31mTemperatu"]
[218.524818, "o", "re.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:32.247\u001b[0m\r\n"]
[218.857166, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.37it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  67%|██████▋   | 4/6 [00:18<00:09,  4.58s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?i"]
[218.857339, "o", "t/s]\u001b[A\r\n"]
[219.864439, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.35it/s]\u001b[A\r\n"]
[220.514135, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:34.248\u001b[0m\r\n\u001b[31;1m 93 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:34.248\u001b[0m\r\n\u001b[31;1m 40 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:34.248\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:34.248\u001b[0m\r\n\u001b[31;1m 64 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:34.248\u001b[0m\r\n"]
[220.860694, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.36it/s]\u001b[A\r\n"]
[221.861964, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.34it/s]\u001b[A\r\n"]
[222.515331, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:36.248\u001b[0m\r\n\u001b[31;1m 98 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:36.248\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:36.248\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:36.248\u001b[0m\r\n\u001b[31;1m 64 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:36.248\u001b[0m\r\n"]
[222.862728, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.36it/s]\u001b[A\r\n"]
[223.864325, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.38it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  83%|████████▎ | 5/6 [00:22<00:04,  4.57s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.36it/s]\u001b[A\r\n"]
[224.515068, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:38.249\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:38.249\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:38.249\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b["]
[224.515234, "o", "0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:38.249\u001b[0m\r\n\u001b[31;1m 63 \u001b[0;31mTempera"]
[224.515332, "o", "ture.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:38.249\u001b[0"]
[224.525982, "o", "m\r\n"]
[224.866262, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.37it/s]\u001b[A\r\n"]
[225.868263, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.24it/s]\u001b[A\r\n"]
[226.517289, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:40.249\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:40.249\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:40.249\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b"]
[226.51738, "o", "[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:40.249\u001b[0m\r\n\u001b[31;1m 65 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:40.249\u001b[0m\r\n"]
[226.870232, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.29it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:03<00:01,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.33it/s]\u001b[A\r\n"]
[227.872093, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.52it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.36it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch: 100%|██████████| 6/6 [00:27<00:00,  4.58s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch: 100%|█████████"]
[227.872392, "o", "█| 6/6 [00:27<00:00,  4.58s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:41 - INFO - transformers.trainer -\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Training completed. Do not forget to share your model on huggingface.co/models =)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:41 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:41 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32/config.json\r\n"]
[228.518301, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:42.251\u001b[0m\r\n\u001b[31;1m 7 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:42.251\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:42.251\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:42.251\u001b[0m\r\n\u001b[31;1m 58 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:42.251\u001b[0m\r\n"]
[228.873747, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:42 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-42_lr-2e-5_TBATCH-32/pytorch_model.bin\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:42 - INFO - __main__ -   *** Evaluate ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:42 - INFO - transformers.trainer -   ***** Running Evaluation *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:42 - INFO - transformers.trainer -     Num examples = 71\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:42 - INFO - transformers.trainer -     Batch size = 8\r\n"]
[229.876692, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation:  56%|█████▌    | 5/9 [00:00<00:00, 49.83it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation: 100%|██████████| 9/9 [00:00<00:00, 50.34it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:42 - INFO - transformers.trainer -   {'eval_loss': 0.6969749132792155, 'eval_acc': 0.38028169014084506, 'epoch': 6.0, 'step': 120}\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:42 - INFO - __main__ -   ***** Eval results wnli *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:42 - INFO - __main__ -     eval_loss = 0.6969749132792155\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:42 - INFO - __main__ -     eval_acc = 0.38028169014084506\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:42 - INF"]
[229.876907, "o", "O - __main__ -     epoch = 6.0\r\n"]
[230.529867, "o", "\r\n\u001b[31;"]
[230.530214, "o", "1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph "]
[230.530647, "o", "2022/07/28 11:59:44.263\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUti"]
[230.540656, "o", "lization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:44.263\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:44.263\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:44.263\u001b[0m\r\n\u001b[31;1m 56 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:44.263\u001b[0m\r\n"]
[230.878069, "o", "2022-07-28 11:59:44 roberta-base lr-2e-5 WNLI seed-42 took 44.3s on mycluster-ray-worker-type-82vph ... 3 of 4 subtasks done\r\n"]
[231.880529, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Node ID: NodeID(527c1193edeefb4906609f81f5feb1196cd59c34221f292157fd2aa8)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m GPU IDs: [0]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Reusing previous existing glue-dataset\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Reusing roberta-base directory\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Processing task WNLI seed 43 with model roberta-base\r\n"]
[232.530374, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:46.263\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:46.263\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:46.263\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:46.263\u001b[0m\r\n\u001b[31;1m 55 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:46.263\u001b[0m\r\n"]
[234.531219, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:48.264\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:48.264\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:48.264\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:48.264\u001b[0m\r\n\u001b[31;1m 55 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:48.264\u001b[0m\r\n"]
[235.892084, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:48 - INFO - transformers.training_args -   PyTorch: setting up devices\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:48 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:48 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_"]
[235.892304, "o", "epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul28_11-59-48_mycluster-ray-worker-type-82vph', logging_first_step=False, logging_steps=500, save_steps=50000, save_total_limit=0, no_cuda=False, seed=43, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:48 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:48 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"architectures\": [\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m     \"RobertaForMaskedLM\"\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   ],\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"attenti"]
[235.892569, "o", "on_probs_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"bos_token_id\": 0,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"eos_token_id\": 2,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"finetuning_task\": \"wnli\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"gradient_checkpointing\": false,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_act\": \"gelu\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_size\": 768,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"initializer_range\": 0.02,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"intermediate_size\": 3072,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"layer_norm_eps\": 1e-05,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"max_position_embeddings\": 514,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"model_type\": \"roberta\",\r\n\u001b[2m\u001b[36m(Process_"]
[235.892652, "o", "task pid=591, ip=10.130.96.40)\u001b[0m   \"num_attention_heads\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_hidden_layers\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"pad_token_id\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"type_vocab_size\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"vocab_size\": 50265\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m }\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:48 - INFO - transformers.configuration_utils -   loading configuration file roberta-base/config.json\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:48 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"architectures\": [\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m     \"RobertaForMaskedLM\"\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   ],\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"att"]
[235.892842, "o", "ention_probs_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"bos_token_id\": 0,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"eos_token_id\": 2,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"gradient_checkpointing\": false,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_act\": \"gelu\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_dropout_prob\": 0.1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"hidden_size\": 768,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"initializer_range\": 0.02,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"intermediate_size\": 3072,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"layer_norm_eps\": 1e-05,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"max_position_embeddings\": 514,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"model_type\": \"roberta\",\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_attention_heads\": 12,\r\n\u001b[2m\u001b[36m(Proc"]
[235.893182, "o", "ess_task pid=591, ip=10.130.96.40)\u001b[0m   \"num_hidden_layers\": 12,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"pad_token_id\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"type_vocab_size\": 1,\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m   \"vocab_size\": 50265\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m }\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:48 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /tmp/cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:48 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /tmp/cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70"]
[235.89332, "o", "bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:49 - INFO - transformers.modeling_utils -   loading weights file roberta-base/pytorch_model.bin\r\n"]
[236.531685, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:50.265\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:50.265\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:50.265\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:50.265\u001b[0m\r\n\u001b[31;1m 54 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:50.265\u001b[0m\r\n"]
[238.532507, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:52.265\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:52.265\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:52.265\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:52.265\u001b[0m\r\n\u001b[31;1m 53 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2"]
[238.543348, "o", "mmycluster-ray-worker-type-82vph 2022/07/28 11:59:52.265\u001b[0m\r\n"]
[240.532913, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:54.266\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:54.266\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:54.266\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:54.266\u001b[0m\r\n\u001b[31;1m 52 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:54.266\u001b[0m\r\n"]
[240.899558, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:54 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip="]
[240.899843, "o", "10.130.96.40)\u001b[0m 07/28/2022 11:59:54 - WARNING - transformers.modeling_utils -   Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:54 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_train_RobertaTokenizer_128_wnli [took 0.036 s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:54 - INFO - transformers.data.datasets.glue -   Loading features from cached file glue_data/WNLI/cached_dev_RobertaTokenizer_128_wnli [took 0.004 s]\r\n"]
[242.533985, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:56.267\u001b[0m\r\n\u001b[31;1m 2 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:56.267\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:56.267\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:56.267\u001b[0m\r\n\u001b[31;1m 53 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:56.267\u001b[0m\r\n"]
[244.534555, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:58.267\u001b[0m\r\n\u001b[31;1m 4 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:58.267\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:58.267\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:58.267\u001b[0m\r\n\u001b[31;1m 53 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 11:59:58.267\u001b[0m\r\n"]
[245.908506, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:58 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:58 - INFO - transformers.trainer -   ***** Running training *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:58 - INFO - transformers.trainer -     Num examples = 635\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:58 - INFO - transformers.trainer -     Num Epochs = 6\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:58 - INFO - transformers.trainer -     Instantaneous batch size per device = 32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:58 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10"]
[245.908856, "o", ".130.96.40)\u001b[0m 07/28/2022 11:59:58 - INFO - transformers.trainer -     Gradient Accumulation steps = 1\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:58 - INFO - transformers.trainer -     Total optimization steps = 120\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 11:59:58 - INFO - transformers.trainer -     Starting fine-tuning.\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:   0%|          | 0/6 [00:00<?, ?it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  3.82it/s]\u001b[A\r\n"]
[246.535071, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:00.268\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:00.268\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:00.268\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:00.268\u001b[0m\r\n\u001b[31;1m 61 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:00.268\u001b[0m\r\n"]
[246.909761, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.13it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:04,  4.24it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.31it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.33it/s]\u001b[A\r\n"]
[247.911028, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.26it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:03,  4.30it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.35it/s]\u001b[A\r\n"]
[248.535806, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:02.268\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:02.268\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:02.268\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:02.268\u001b[0m\r\n\u001b[31;1m 62 \u001b[0;31mTemperature.GPU"]
[248.536054, "o", "\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:02.268\u001b[0m\r\n"]
[248.913002, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.31it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:03<00:01,  4.31it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.35it/s]\u001b[A\r\n"]
[249.914557, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.33it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.50it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.34it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  17%|█▋        | 1/6 [0"]
[249.914831, "o", "0:04<00:23,  4.61s/it]\r\n"]
[250.5365, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:04.269\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:04.269\u001b[0m\r\n\u001b[31;1m 40 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:04.269\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:04.269\u001b[0m\r\n\u001b[31;1m 63 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:04.269\u001b[0m\r\n"]
[250.915866, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.34it/s]\u001b[A\r\n"]
[251.917764, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.38it/s]\u001b[A\r\n"]
[252.536914, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:06.269\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:06.269\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2m"]
[252.537149, "o", "mycluster-ray-worker-type-82vph 2022/07/28 12:00:06.269\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:06.269\u001b[0m\r\n\u001b[31;1m 64 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:06.269\u001b[0m\r\n"]
[252.91955, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.39it/s]\u001b[A\r\n"]
[253.920878, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.38it/s]\u001b[A\r\n"]
[254.53778, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:08.270\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:08.270\u001b[0m\r\n\u001b[31;1m 40 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:08.270\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:08.270\u001b[0m\r\n\u001b[31;1m 65 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:08.270\u001b[0m\r\n"]
[254.92325, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.54it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.40it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  33%|███▎      | 2/6 [00:09<00:18,  4.57s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.40it/s]\u001b[A\r\n"]
[255.925017, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.40it/s]\u001b[A\r\n"]
[256.538146, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:10.270\u001b[0m\r\n\u001b[31;1m 93 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:10.270\u001b[0m\r\n\u001b[31;1m 40 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:10.270\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:10.270\u001b[0m\r\n\u001b[31;1m 65 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:10.270\u001b[0m\r\n"]
[256.926551, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.40it/s]\u001b[A\r\n"]
[257.927066, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.34it/s]\u001b[A\r\n"]
[258.53834, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:12.271\u001b[0m\r\n\u001b[31;1m 97 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:12.271\u001b[0m\r\n\u001b[31;1m 37 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:12.271\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:12.271\u001b[0m\r\n\u001b[31;1m 65 \u001b["]
[258.538577, "o", "0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:12.271\u001b[0m\r\n"]
[258.928546, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.39it/s]\u001b[A\r\n"]
[259.930351, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.58it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.41it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  50%|█████     | 3/6 [00:13<00:13,  4.55s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.40it/s]\u001b[A\r\n"]
[260.543551, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:14.272\u001b[0m\r\n\u001b[31;1m 95 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:14.272\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:14.272\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:14.272\u001b[0m\r\n\u001b[31;1m 64 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:14.272\u001b[0m\r\n"]
[260.931581, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.31it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.35it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.40it/s]\u001b[A\r\n"]
[261.934512, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.41it/s]\u001b[A\r\n"]
[262.539413, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:16.272\u001b[0m\r\n\u001b[31;1m 83 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:16.272\u001b[0m\r\n\u001b[31;1m 37 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:16.272\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:16.272\u001b[0m\r\n\u001b[31;1m 66 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:16.272\u001b[0m\r\n"]
[262.936534, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.37it/s]\u001b[A\r\n"]
[263.9382, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.53it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.41it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  67%|██████▋   | 4/6 [00:18<00:09,  4.55s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n"]
[264.54063, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:18.273\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:18.273\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:18.273\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:18.273\u001b[0m\r\n\u001b[31;1m 66 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:18.273\u001b[0m\r\n"]
[264.939884, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.46it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.38it/s]\u001b[A\r\n"]
[265.941141, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n"]
[266.540672, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:20.273\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:20.273\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:20.273\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:20.273\u001b[0m\r\n\u001b[31;1m 67 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:20.273\u001b[0m\r\n"]
[266.942235, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.38it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.38it/s]\u001b[A\r\n"]
[267.942716, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.42it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.40it/s]\u001b[A\r\n"]
[268.541343, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:22.273\u001b[0m\r\n\u001b[31;1m 89 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:22.273\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:22.273\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:22.273\u001b[0m\r\n\u001b[31;1m 67 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:22.273\u001b[0m\r\n"]
[268.944403, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.56it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.42it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch:  83%|████████▎ | 5/6 [00:22<00:04,  4.54s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:   5%|▌         | 1/20 [00:00<00:04,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  10%|█         | 2/20 [00:00<00:04,  4.37it/s]\u001b[A\r\n"]
[269.94607, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  15%|█▌        | 3/20 [00:00<00:03,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  20%|██        | 4/20 [00:00<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  25%|██▌       | 5/20 [00:01<00:03,  4.41it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  30%|███       | 6/20 [00:01<00:03,  4.40it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  35%|███▌      | 7/20 [00:01<00:02,  4.37it/s]\u001b[A\r\n"]
[270.542329, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:24.274\u001b[0m\r\n\u001b[31;1m 86 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:24.274\u001b[0m\r\n\u001b[31;1m 39 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:24.274\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:24.274\u001b[0m\r\n\u001b[31;1m 66 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:24.274\u001b[0m\r\n"]
[270.946769, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  40%|████      | 8/20 [00:01<00:02,  4.39it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  45%|████▌     | 9/20 [00:02<00:02,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  50%|█████     | 10/20 [00:02<00:02,  4.34it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  55%|█████▌    | 11/20 [00:02<00:02,  4.36it/s]\u001b[A\r\n"]
[271.949148, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  60%|██████    | 12/20 [00:02<00:01,  4.36it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  65%|██████▌   | 13/20 [00:02<00:01,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  70%|███████   | 14/20 [00:03<00:01,  4.37it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  75%|███████▌  | 15/20 [00:03<00:01,  4.36it/s]\u001b[A\r\n"]
[272.542702, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:26.275\u001b[0m\r\n\u001b[31;1m 88 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:26.275\u001b[0m\r\n\u001b[31;1m 38 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:26.275\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:26.275\u001b[0m\r\n\u001b[31;1m 67 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:26.275\u001b[0m\r\n"]
[272.950325, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  80%|████████  | 16/20 [00:03<00:00,  4.25it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  85%|████████▌ | 17/20 [00:03<00:00,  4.28it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  90%|█████████ | 18/20 [00:04<00:00,  4.30it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration:  95%|█████████▌| 19/20 [00:04<00:00,  4.32it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.50it/s]\u001b[A\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Iteration: 100%|██████████| 20/20 [00:04<00:00,  4.38it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch: 100%|██████████| 6/6 [00:27<00:00,  4.55s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Epoch: 100%|█████████"]
[272.950469, "o", "█| 6/6 [00:27<00:00,  4.55s/it]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:26 - INFO - transformers.trainer -\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Training completed. Do not forget to share your model on huggingface.co/models =)\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:26 - INFO - transformers.trainer -   Saving model checkpoint to result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:26 - INFO - transformers.configuration_utils -   Configuration saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32/config.json\r\n"]
[273.952822, "o", "\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:27 - INFO - transformers.modeling_utils -   Model weights saved in result/roberta-base/WNLI/lr-2e-5/wnli_seed-43_lr-2e-5_TBATCH-32/pytorch_model.bin\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:27 - INFO - __main__ -   *** Evaluate ***\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:27 - INFO - transformers.trainer -   ***** Running Evaluation *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:27 - INFO - transformers.trainer -     Num examples = 71\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:27 - INFO - transformers.trainer -     Batch size = 8\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation:   0%|          | 0/9 [00:00<?, ?it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 50.19it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m Evaluation: 100%"]
[273.9531, "o", "|██████████| 9/9 [00:00<00:00, 50.29it/s]\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:27 - INFO - transformers.trainer -   {'eval_loss': 0.6930272446738349, 'eval_acc': 0.4788732394366197, 'epoch': 6.0, 'step': 120}\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:27 - INFO - __main__ -   ***** Eval results wnli *****\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:27 - INFO - __main__ -     eval_loss = 0.6930272446738349\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:27 - INFO - __main__ -     eval_acc = 0.4788732394366197\r\n\u001b[2m\u001b[36m(Process_task pid=591, ip=10.130.96.40)\u001b[0m 07/28/2022 12:00:27 - INFO - __main__ -     epoch = 6.0\r\n"]
[274.543959, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:28.275\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:28.275\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:28.275\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:28.275\u001b[0m\r\n\u001b[31;1m 59 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:28.275\u001b[0m\r\n"]
[275.954317, "o", "2022-07-28 12:00:29 roberta-base lr-2e-5 WNLI seed-43 took 44.0s on mycluster-ray-worker-type-82vph ... 4 of 4 subtasks done\r\n"]
[276.543296, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:30.276\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:30.276\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:30.276\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:30.276\u001b[0m\r\n\u001b[31;1m 58 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:30.276\u001b[0m\r\n"]
[278.543633, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:32.276\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:32.276\u001b[0m\r\n\u001b[31;"]
[278.543752, "o", "1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:32.276\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:32.276\u001b[0m\r\n\u001b[31;1m 57 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:32.276\u001b[0m\r\n"]
[279.298914, "o", "\r\n"]
[279.298963, "o", "✨ Guidebook successful\r\n"]
[280.544327, "o", "\r\n\u001b[31;1m Tesla V100-SXM2-16GB \u001b[0;31mGPUType\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:34.277\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:34.277\u001b[0m\r\n\u001b[31;1m 0 % \u001b[0;31mUtilization.Memory\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:34.277\u001b[0m\r\n\u001b[31;1m 16384 MiB \u001b[0;31mMemory.Total\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:34.277\u001b[0m\r\n\u001b[31;1m 56 \u001b[0;31mTemperature.GPU\t\t\t\u001b[0;2mmycluster-ray-worker-type-82vph 2022/07/28 12:00:34.277\u001b[0m\r\n"]
[280.731817, "o", "\u001b[32mok\u001b[39m\r\n"]
[280.732227, "o", "\u001b[?25h\u001b[?25h\u001b[?25h"]
[280.73226, "o", "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h"]
[280.732274, "o", "\u001b[?25h"]
[280.732461, "o", "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h"]
[280.732563, "o", "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h"]
[280.732707, "o", "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h"]
[280.732857, "o", "\u001b[?25h"]
[280.746048, "o", "bash-3.2$ "]
[282.089833, "o", "exit\r\n"]
